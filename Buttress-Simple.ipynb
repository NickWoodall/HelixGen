{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from math import cos,sin,tan,asin,acos,radians,sqrt,degrees,atan,atan2,copysign\n",
    "import numpy as np\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "import random\n",
    "import time\n",
    "import timeit\n",
    "import math\n",
    "import localization as lx\n",
    "import gzip\n",
    "\n",
    "import util.npose_util as nu\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "from sklearn.manifold import MDS\n",
    "import argparse\n",
    "from functools import partial\n",
    "from itertools import starmap,repeat\n",
    "\n",
    "from pymol import cmd, stored, selector\n",
    "\n",
    "import GenerateEndpoints as ge\n",
    "import HelixFit as hf\n",
    "\n",
    "#reference helix for propogation\n",
    "zero_ih = nu.npose_from_file('util/zero_ih.pdb')\n",
    "tt = zero_ih.reshape(int(len(zero_ih)/5),5,4)\n",
    "stub = tt[7:10].reshape(15,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load distance maps\n",
    "def load_distance_map(name, dm_file='data/Fits_4H_dm_phi.npz'):\n",
    "    rr = np.load(dm_file, allow_pickle=True)\n",
    "    X_train, y_train , featNames = [rr[f] for f in rr.files]\n",
    "    \n",
    "    return X_train[y_train==name][:,:-4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkLoss2(testArray,refArray,mask):\n",
    "\n",
    "    return np.sum(np.square(refArray-testArray)*mask,axis=1)\n",
    "\n",
    "@tf.function\n",
    "def maskLoss(y_actual, y_pred,mask):\n",
    "    custom_loss_val = tf.multiply(mask,tf.square(y_actual-y_pred))\n",
    "    return custom_loss_val\n",
    "\n",
    "def buttLoss(recon,mask,refMap,input_z=None,rate=0.05,batch_size=32,cycles=100):\n",
    "\n",
    "    recon.batch_size = batch_size\n",
    "    vecDes = recon.mm.transform(np.repeat(refMap.reshape(1,-1) , batch_size, axis=0))\n",
    "    \n",
    "    mask =  np.repeat(np.array(mask).reshape(1,-1) , batch_size,axis=0)\n",
    "\n",
    "    v=tf.convert_to_tensor(vecDes)\n",
    "    m=tf.convert_to_tensor(mask)\n",
    "    m2=tf.cast(m, tf.float32)\n",
    "    v=tf.cast(v,tf.float32)\n",
    "\n",
    "    if input_z is None:\n",
    "        input_z = tf.random.uniform(shape=(batch_size,recon.z_size), minval=-1, maxval=1)\n",
    "\n",
    "\n",
    "    rate = tf.Variable(0.1)\n",
    "    input_z_var = tf.Variable(input_z)\n",
    "    g_o = recon.g(input_z_var)\n",
    "    print('Loss before ')\n",
    "    print(checkLoss2(g_o,v,m2))\n",
    "    print(np.sum(checkLoss2(g_o,v,m2)))\n",
    "\n",
    "    z=[]\n",
    "    grads = []\n",
    "\n",
    "    for t in range(1,cycles):\n",
    "\n",
    "        #compute Loss\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            g_tape.watch(input_z_var)\n",
    "            g_o = recon.g(input_z_var)\n",
    "            masked_loss = maskLoss(v,g_o,m2)\n",
    "\n",
    "        g_grads = g_tape.gradient(masked_loss, input_z_var)\n",
    "\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=rate)\n",
    "        #optimizer = tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95)\n",
    "        #optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "        optimizer.apply_gradients(zip([g_grads],[input_z_var]))\n",
    "\n",
    "        if t%10 == 0:\n",
    "            z.append(input_z_var)\n",
    "            grads.append(g_grads)\n",
    "\n",
    "    z.append(input_z_var)\n",
    "    grads.append(g_grads)\n",
    "    recon.input_z = input_z_var\n",
    "    print('Loss after optimization')\n",
    "    loss_final = checkLoss2(g_o,v,m2)\n",
    "    print(loss_final)\n",
    "    print(np.sum(loss_final))\n",
    "    #print(f'Reconstruction Error: {sum(recon.reconstructionError()):.2f}')\n",
    "\n",
    "\n",
    "    return recon, loss_final, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buttress1_2_reference_protein(batch,refName='00d94cdcf922f50c6b9c82a8b57d6515_0001',\n",
    "                                  gen=\"data/BestGenerator\",cycles=1000):\n",
    "    \n",
    "    refMap = load_distance_map(refName)\n",
    "    brec = ge.BatchRecon(gen)\n",
    "    brec.generate(z=12,batch_size=batch)\n",
    "    \n",
    "    mask1   = np.array([1,1,1,0,0,0,0,\n",
    "                       1,1,0,0,0,0,\n",
    "                       1,0,0,0,0,\n",
    "                       0,0,0,0,\n",
    "                       0,0,0,\n",
    "                       0,0,\n",
    "                       0])\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    brec, loss_final, z = buttLoss(brec, mask1, refMap,input_z=brec.input_z,batch_size=batch,cycles=cycles)\n",
    "    end = time.time()\n",
    "    print('Elapsed time:',end - start)\n",
    "    brec.generate(z=12,input_z=z[-1],batch_size=batch)\n",
    "    brec.MDS_reconstruct_()\n",
    "    brec.reconstructionError()\n",
    "    brec.to_npose()\n",
    "    \n",
    "    return brec, loss_final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_helices(ref,pDirec,helix_list=[1,2],outDirec='output/'):\n",
    "    \"\"\"Aligns proteins in pDirec (directory) to ref (file) based on helices in helix list [starts at 1]\"\"\"\n",
    "    cmd.delete(\"all\")\n",
    "    cmd.load(f'{ref}.pdb')\n",
    "    fileList = os.listdir(pDirec)\n",
    "    refName = os.path.basename(ref)\n",
    "    \n",
    "    for x in fileList:\n",
    "        cmd.load(f'{pDirec}/{x}')\n",
    "        cmd.save(f'{outDirec}/buttressTest.pse')\n",
    "        pairFit_Helix(refName,x[:-4],helix_fits=helix_list) #remove .pdb for pymol\n",
    "    \n",
    "    cmd.save(f'{outDirec}/buttressTest.pse')\n",
    "\n",
    "#visualize \n",
    "def get_HelixList(name):\n",
    "    stored.resi = []\n",
    "    cmd.iterate_state(1, selector.process(f\"{name} and ss 'H' and n. CA\"), \"stored.resi.append(resi)\")\n",
    "\n",
    "    helixRes = []\n",
    "    xNow = -1\n",
    "    for x in stored.resi:\n",
    "        if int(x)> xNow:\n",
    "            xNow = int(x)\n",
    "            helixRes.append([])\n",
    "        helixRes[-1].append(int(x))\n",
    "        xNow = xNow+1\n",
    "\n",
    "    warn = False\n",
    "\n",
    "    for x in helixRes:\n",
    "        if len(x) < 4:\n",
    "            warn=True\n",
    "    if not len(helixRes) == 4:\n",
    "        warn=True\n",
    "\n",
    "    if warn:\n",
    "        print(f'Check{name}: Helices not as expected')\n",
    "\n",
    "    return helixRes\n",
    "\n",
    "def list_alignHelices(name1, name2, helixNum=1):\n",
    "\n",
    "    hList1 = get_HelixList(name1)\n",
    "    hList2 = get_HelixList(name2)\n",
    "    #residues for helix1\n",
    "    p1_h = hList1[helixNum-1]\n",
    "    p2_h = hList2[helixNum-1]\n",
    "\n",
    "    front = True\n",
    "\n",
    "    while not len(p1_h) == len(p2_h):\n",
    "        if len(p1_h)>len(p2_h):\n",
    "            if front:\n",
    "                p1_h = p1_h[1:]\n",
    "            else:\n",
    "                p1_h = p1_h[:-1]\n",
    "\n",
    "            #front = get_ipython().getoutput('front')\n",
    "        else:\n",
    "            if front:\n",
    "                p2_h = p2_h[1:]\n",
    "            else:\n",
    "                p2_h = p2_h[:-1]\n",
    "\n",
    "            #front = get_ipython().getoutput('front')\n",
    "\n",
    "    return p1_h, p2_h\n",
    "\n",
    "def hSel(hListList, name):\n",
    "\n",
    "    resString = \"\"\n",
    "\n",
    "    for x in hListList:\n",
    "        resString = f'{resString}+{x[0]}-{x[-1]}'\n",
    "\n",
    "    resString = resString[1:]\n",
    "\n",
    "    return f'{name} and resi {resString} and name CA'\n",
    "\n",
    "\n",
    "\n",
    "def pairFit_Helix(prot1,prot2,helix_fits=[1,2]):\n",
    "\n",
    "    #moves prot2 onto prot1\n",
    "    pairList1 = []\n",
    "    pairList2 = []\n",
    "    \n",
    "    for x in helix_fits:\n",
    "        p1_h, p2_h= list_alignHelices(prot1,prot2, helixNum=x)\n",
    "        pairList1.append(p1_h)\n",
    "        pairList2.append(p2_h)\n",
    "\n",
    "    rms = cmd.pair_fit(hSel(pairList2, prot2), hSel(pairList1, prot1))\n",
    "    return rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Loss before \n",
      "[0.17735921 0.42615056 0.21554503 1.2015755  1.1099789  0.7312604\n",
      " 1.0891759  0.67656124 0.48045844 0.55875635 0.502463   0.57047135\n",
      " 0.71845055 1.1743217  1.7404813  0.81797373 0.7676634  0.815336\n",
      " 0.40669316 1.4294142  0.42514682 2.060707   0.82784986 0.26991677\n",
      " 0.42076752 0.907427   0.48394373 0.67887866 1.0502466  0.45599973\n",
      " 0.9234287  0.57485247]\n",
      "24.689255\n",
      "Loss after optimization\n",
      "[8.6480338e-04 1.2123124e-03 3.2869005e-03 4.0789703e-03 9.2235496e-03\n",
      " 8.0878986e-04 8.6468935e-04 8.0889473e-03 1.8287174e-03 1.7425783e-04\n",
      " 4.7285599e-03 8.7149808e-04 9.0692483e-05 9.5909154e-03 9.7104469e-03\n",
      " 1.3393452e-03 3.3049388e-03 1.4807147e-03 1.3184035e-03 1.6856110e-02\n",
      " 2.7925179e-03 2.2415118e-02 1.3153104e-02 6.3328100e-03 4.4639339e-03\n",
      " 3.0029232e-03 7.6529197e-04 2.8226383e-03 2.3138814e-04 5.4802084e-03\n",
      " 5.5708867e-03 2.0946379e-04]\n",
      "0.14696385\n",
      "Elapsed time: 2.5104010105133057\n"
     ]
    }
   ],
   "source": [
    "refName='00d94cdcf922f50c6b9c82a8b57d6515_0001'\n",
    "brec, loss_final = buttress1_2_reference_protein(32,refName='00d94cdcf922f50c6b9c82a8b57d6515_0001',\n",
    "                                  gen=\"data/BestGenerator\",cycles=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176.28571428571428"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24.68/0.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "outDirec = 'output/'\n",
    "for i,c in enumerate(brec.npose_list):\n",
    "    if loss_final[i]<.005:\n",
    "        nu.dump_npdb(c,f'{outDirec}build{i}.pdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'refName' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1f28b75fb943>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'data/4H_dataset/models/{refName}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpDirec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'output/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0malign_helices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpDirec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhelix_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'refName' is not defined"
     ]
    }
   ],
   "source": [
    "ref = f'data/4H_dataset/models/{refName}'\n",
    "pDirec = 'output/'\n",
    "align_helices(ref,pDirec,helix_list=[1,2])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fa_tfpy",
   "language": "python",
   "name": "fa_tfpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
