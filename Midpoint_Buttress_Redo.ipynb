{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device name CPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    device_name = tf.test.gpu_device_name()\n",
    "else:\n",
    "    device_name = 'CPU'\n",
    "device_name = 'CPU' \n",
    "print(f'device name {device_name}')\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from math import cos,sin,tan,asin,acos,radians,sqrt,degrees,atan,atan2,copysign\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "import random\n",
    "import time\n",
    "import timeit\n",
    "import math\n",
    "import localization as lx\n",
    "import gzip\n",
    "\n",
    "import util.npose_util as nu\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "\n",
    "import joblib\n",
    "from sklearn.manifold import MDS\n",
    "import argparse\n",
    "from functools import partial\n",
    "from itertools import starmap,repeat,permutations\n",
    "\n",
    "from pymol import cmd, stored, selector\n",
    "\n",
    "import GenerateEndpoints as ge\n",
    "import HelixFit as hf\n",
    "import FitTransform as ft\n",
    "\n",
    "import seaborn as sns\n",
    "import util.RotationMethods as rm\n",
    "\n",
    "#reference helix for propogation\n",
    "zero_ih = nu.npose_from_file('util/zero_ih.pdb')\n",
    "tt = zero_ih.reshape(int(len(zero_ih)/5),5,4)\n",
    "stub = tt[7:10].reshape(15,4)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load distance maps and endpoints dataset\n",
    "def load_distance_map(name, dm_file='data/Fits_4H_dm_phi.npz'):\n",
    "    rr = np.load(dm_file, allow_pickle=True)\n",
    "    X_train, y_train , featNames = [rr[f] for f in rr.files]\n",
    "    \n",
    "    \n",
    "    return X_train[y_train==name][:,:-4]\n",
    "\n",
    "# dm_file = 'data/Fits_4H_dm_phi.npz'\n",
    "# rr = np.load(dm_file, allow_pickle=True)\n",
    "# X_train, y_train , featNames = [rr[f] for f in rr.files]\n",
    "# = 'data/4H_dataset/models/'\n",
    "# cmd.load(f'{model_direc}{y_train[0]}.pdb')\n",
    "# cmd.save(f'output/test.pdb')\n",
    "\n",
    "#endpoints for data set \n",
    "# Fits4H_file = 'data/Fits_4H.csv'\n",
    "# dfRead = pd.read_csv(Fits4H_file)\n",
    "# df1 = ft.prepData_Str(dfRead,rmsd_filter=100)\n",
    "# df2 = ft.EndPoint(df1)\n",
    "# ep = df2.to_numpy()[:,:24].astype(float).reshape((-1,8,3))\n",
    "# X = ep\n",
    "# np.savez_compressed('data/ep_for_X.npz', ep=X)\n",
    "rr = np.load(f'data/ep_for_X.npz', allow_pickle=True)\n",
    "X = [rr[f] for f in rr.files][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_helix_ep(ep_in,helices_desired=[0,1],num_helices=4):\n",
    "    \n",
    "    num_ep = num_helices*2\n",
    "    hi = np.array(helices_desired,dtype=int)\n",
    "    h_ep = np.array(range(num_ep)).reshape((-1,2)) #generate helix to endpoint mapping\n",
    "    \n",
    "    #alternate example for indexing batch of X \n",
    "    #X.reshape((X.shape[0],-1))[:,indexarray]\n",
    "    \n",
    "    #select desired endpoints from  batch of endpoints\n",
    "    return ep_in[np.ix_(np.array(range(ep_in.shape[0])),h_ep[hi].flatten(), np.array(range(ep_in.shape[2])))]\n",
    "    \n",
    "def get_midpoint(ep_in,helices_desired=[0,1],num_helices=4):\n",
    "    \n",
    "    num_ep = num_helices*2\n",
    "    \n",
    "    ind_ep = index_helix_ep(ep_in, helices_desired=helices_desired, num_helices=4)\n",
    "    \n",
    "    #calculate midpoint\n",
    "    midpoint = ind_ep.sum(axis=1)/np.repeat(ind_ep.shape[1], ind_ep.shape[2])\n",
    "    \n",
    "    return midpoint\n",
    "\n",
    "def get_stubs_from_points(ep_in,index=[0,1,2]):\n",
    "#def get_stubs_from_n_ca_c(n, ca, c):\n",
    "    \"\"\"Modified from Brian's npose code  get_stubs_from_n_ca_c, index references 3 points, to define plane.\n",
    "    \"\"\"\n",
    "    e1 = ep_in[:,index[1]]-ep_in[:,index[0]]\n",
    "    e1 = np.divide( e1, np.linalg.norm(e1, axis=1)[..., None] )\n",
    "\n",
    "    e3 = np.cross( e1, ep_in[:,index[2]]-ep_in[:,index[0]], axis=1 )\n",
    "    e3 = np.divide( e3, np.linalg.norm(e3, axis=1)[..., None] )\n",
    "\n",
    "    e2 = np.cross( e3, e1, axis=1 )\n",
    "\n",
    "    stub = np.zeros((len(ep_in), 4, 4))\n",
    "    stub[...,:3,0] = e1\n",
    "    stub[...,:3,1] = e2\n",
    "    stub[...,:3,2] = e3\n",
    "    stub[...,:3,3] = ep_in[:,index[1]]\n",
    "    stub[...,3,3] = 1.0\n",
    "\n",
    "    return stub\n",
    "\n",
    "def xform_npose_2batch(xform, npose):\n",
    "    #single batch code  util.npose_util as xform_npose\n",
    "    return np.matmul(np.repeat(xform[:,np.newaxis,...],npose.shape[1],axis=1),npose[...,None]).squeeze(-1)\n",
    "\n",
    "def xform_to_z_plane(mobile, index_mobile=[0,1,2]):\n",
    "    \"\"\"rotate points into the z-plane for trilaterization. needs additional translation/reflection\"\"\"\n",
    "\n",
    "    mobile_stub = get_stubs_from_points(mobile, index=index_mobile)\n",
    "    mobile_stub_inv = np.linalg.inv(mobile_stub)\n",
    "    \n",
    "    z_plane_ref = np.repeat(np.array([[[0,0,0],[1,0,0],[1,1,0]]]), mobile.shape[0],axis=0)\n",
    "\n",
    "    ref_stub = get_stubs_from_points(z_plane_ref, index=[0,1,2])\n",
    "\n",
    "    xform = ref_stub @ mobile_stub_inv\n",
    "\n",
    "    return xform\n",
    "\n",
    "\n",
    "def rotate_base_tri_Zplane(endpoint_midpoints, target_point=4, index_mobile=[1,2,3], returnRotMat=False):\n",
    "    \"\"\"rotate points into the z-plane for trilaterization. Target point ensures that point is positive in Z\"\"\"\n",
    "    tp = target_point #target point\n",
    "    zplanexform = xform_to_z_plane(endpoint_midpoints,index_mobile=index_mobile) #one index start base triangle, default\n",
    "    #add one for npose rot calc\n",
    "    npose = np.concatenate((endpoint_midpoints, np.ones((endpoint_midpoints.shape[0],\n",
    "                                                         endpoint_midpoints.shape[1],1))),axis=2) \n",
    "    rot = xform_npose_2batch(zplanexform,npose) # double batch matrix multiplication, see npose, for one batch\n",
    "\n",
    "    #translate X domain to place first index of \"index_mobile\" to 0,0,0\n",
    "    rot[:,:,0] = rot[:,:,0]-np.expand_dims(rot[:,index_mobile[0],0],axis=1)\n",
    "    #based on target point guaranteed to be positive\n",
    "    #reflect new points across the z axis to positive if negative to match just choosing positive solutions\n",
    "    rot[...,2][rot[:,tp,2]<0] = -rot[...,2][rot[:,tp,2]<0]\n",
    "    \n",
    "    if not returnRotMat:\n",
    "        return rot[...,:3] #remove npose rotate dimension\n",
    "    else:\n",
    "        return rot[...,:3], zplanexform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#methods to index needed indices from generator\n",
    "\n",
    "def helix_dindex(helices_to_keep, num_helices=4, intraHelixDist=True):\n",
    "    \"\"\"Get index values for parts of the distance map\"\"\"\n",
    "    \n",
    "    #prep indices for distance map\n",
    "    num_ep = num_helices*2\n",
    "    mat_ind = np.array(range((num_ep)**2)).reshape((num_ep,num_ep))\n",
    "    iu1 = np.triu_indices(num_ep, 1)\n",
    "    \n",
    "    helix_used = np.array(helices_to_keep,dtype=int)\n",
    "    \n",
    "    h_ep = np.array(range(num_ep)).reshape((-1,2)) #generate helix to endpoint mapping\n",
    "    \n",
    "    tot_ind = []\n",
    "    \n",
    "    if intraHelixDist:\n",
    "        #get indices of distance map that correspond to each helix, overlap is distances between specified endpoints\n",
    "        for x in helix_used:\n",
    "            new_ind = np.intersect1d(mat_ind[h_ep[x]], mat_ind.T[h_ep[x]])\n",
    "            tot_ind.extend(new_ind)\n",
    "    \n",
    "    \n",
    "    for x in permutations(helix_used,2):\n",
    "        new_ind = np.intersect1d(mat_ind[h_ep[x[0]]], mat_ind.T[h_ep[x[1]]])\n",
    "        tot_ind.extend(new_ind)\n",
    "    \n",
    "    #convert to generator indices (indices of iu1 array)\n",
    "    out_ind = []\n",
    "    for x in tot_ind:\n",
    "        if len(np.nonzero(mat_ind[iu1]==x)[0])>0:\n",
    "            out_ind.append(np.nonzero(mat_ind[iu1]==x))\n",
    "\n",
    "    return np.sort(np.array(out_ind).flatten())\n",
    "\n",
    "\n",
    "def point_dindex(target_points, ref=[4], num_helices = 4):\n",
    "    \n",
    "    num_ep = num_helices*2\n",
    "    mat_ind = np.array(range((num_ep)**2)).reshape((num_ep,num_ep))\n",
    "    iu1 = np.triu_indices(num_ep, 1)\n",
    "    \n",
    "    dindex = []\n",
    "    \n",
    "    for tp in target_points:\n",
    "        for ref_ind in ref:\n",
    "            dindex.append(mat_ind[ref_ind,tp]) #indices for distances to target point\n",
    "    \n",
    "    dindex = np.array(dindex)\n",
    "    \n",
    "    out_ind = []\n",
    "    for x in dindex.flatten():\n",
    "        out_ind.append(np.nonzero(mat_ind[iu1]==x))\n",
    "        \n",
    "    out_ind = np.array(out_ind)\n",
    "    \n",
    "    return out_ind.reshape((len(target_points),-1))\n",
    "\n",
    "def target_dindex(target_points, oneRef = True, num_helices = 5, baseTri_out=True):\n",
    "    \"\"\"Distance map indices for base triangle and output distance map\"\"\"\n",
    "    \n",
    "    num_ep = num_helices*2\n",
    "    mat_ind = np.array(range((num_ep)**2)).reshape((num_ep,num_ep))\n",
    "    iu1 = np.triu_indices(num_ep, 1)\n",
    "\n",
    "    if oneRef:\n",
    "        ref = [1,2,3]\n",
    "        base_tri = [mat_ind[1][2],mat_ind[2][3],mat_ind[1][3]] #p1 to p2, p2 to p3, p1 to p3\n",
    "        \n",
    "    else:\n",
    "        ref = [0,1,2]\n",
    "        base_tri = [mat_ind[0][1],mat_ind[1][2],mat_ind[0][3]] #p0 to p1, p1 to p2, p0 to p3\n",
    "    \n",
    "    dindex = []\n",
    "    \n",
    "    for tp in target_points:\n",
    "        dindex.append(mat_ind[ref,tp]) #indices for distances to target point\n",
    "    \n",
    "    dindex = np.array(dindex)\n",
    "    \n",
    "    out_ind = []\n",
    "    for x in dindex.flatten():\n",
    "        out_ind.append(np.nonzero(mat_ind[iu1]==x))\n",
    "        \n",
    "    out_ind = np.array(out_ind)\n",
    "    \n",
    "    return out_ind.reshape((-1,len(base_tri))),base_tri\n",
    "\n",
    "def minMax_indices(distance_index, point_index, minmax_obj):\n",
    "    \n",
    "    #assemble conversions \n",
    "    #converts output from generator back to real distances\n",
    "    dMin_all = tf.convert_to_tensor(minmax_obj.data_min_, dtype=tf.float32)\n",
    "    mScale_all = tf.convert_to_tensor(minmax_obj.scale_, dtype = tf.float32)\n",
    "    mMin = tf.convert_to_tensor(minmax_obj.feature_range[0], dtype = tf.float32)\n",
    "\n",
    "    #index just the distances we need for calculation\n",
    "    dMin = tf.gather(dMin_all, distance_index,axis=0)\n",
    "    mScale = tf.gather(mScale_all, distance_index,axis=0)\n",
    "\n",
    "    #indexes we need to determine the +/- z value of the new points\n",
    "    pindex = point_dindex([5,6,7], ref=[4], num_helices = 4)\n",
    "    dMin_nwp = tf.gather(dMin_all, point_index,axis=0)\n",
    "    mScale_nwp = tf.gather(mScale_all, point_index,axis=0)\n",
    "    \n",
    "    return dMin, mScale, mMin, dMin_nwp,  mScale_nwp \n",
    "\n",
    "def ref_distmap_index(distances, num_helices = 4):\n",
    "    \n",
    "    num_ep = num_helices*2\n",
    "    mat_ind = np.array(range((num_ep)**2)).reshape((num_ep,num_ep))\n",
    "    iu1 = np.triu_indices(num_ep, 1)\n",
    "    iu1_flat = iu1[0]*num_ep+iu1[1]\n",
    "    \n",
    "    return distances[np.ix_(range(distances.shape[0]),iu1_flat)]\n",
    "\n",
    "def convert_dMat_to_iu1_index(indices_in, num_helices = 4):\n",
    "    \"\"\"Converts indices on flattened distance index to iu1 single indices\"\"\"\n",
    "    \n",
    "    \n",
    "    conv_array = np.array(indices_in).flatten()\n",
    "    \n",
    "    num_ep = num_helices*2\n",
    "    mat_ind = np.array(range((num_ep)**2)).reshape((num_ep,num_ep))\n",
    "    iu1 = np.triu_indices(num_ep, 1)\n",
    "    \n",
    "    #convert to generator indices (indices of iu1 array)\n",
    "    out_ind = []\n",
    "    for x in conv_array:\n",
    "        if len(np.nonzero(mat_ind[iu1]==x)[0])>0:\n",
    "            out_ind.append(np.nonzero(mat_ind[iu1]==x))\n",
    "            \n",
    "    out_ind = np.array(out_ind)\n",
    "        \n",
    "    return out_ind.reshape(conv_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_base_triangle_trilateriation(dindex, base_tri, distance_map):\n",
    "    \"\"\"Return x,y,z coords on z-plane of base triangle of tetrahedron from a distance map.\"\"\"\n",
    "    \n",
    "#     dindex, base_tri = target_dindex(targ_dind, oneRef = oneRef, num_helices = num_helices)\n",
    "# #     print(dindex)\n",
    "# #     print(base_tri)\n",
    "    \n",
    "    #test case input data: prep base triangles for trilateration at zplane, (0,0,0) (dvar,0,0) (ivar,jvar,0)\n",
    "    desired_dm = distance_map[:, base_tri] #base tri from dindex\n",
    "\n",
    "    dvar_index = tf.convert_to_tensor(0 ,dtype=tf.int32)\n",
    "    s2_index = tf.convert_to_tensor(2 ,dtype=tf.int32) # we would like the angle across from side 2\n",
    "    s3_index = tf.convert_to_tensor(1 ,dtype=tf.int32)\n",
    "\n",
    "    #x value representing center of 2nd sphere at (dvar,0,0) aka s1\n",
    "    dvar = tf.reshape(tf.gather(desired_dm, dvar_index,axis=1),(-1,1)) #side 1\n",
    "    s2 = tf.reshape(tf.gather(desired_dm,   s2_index,axis=1),(-1,1))\n",
    "    s3 = tf.reshape(tf.gather(desired_dm,   s3_index,axis=1),(-1,1))\n",
    "\n",
    "    #calculate the opposite angle of the the third side of base triangle using law of cosines\n",
    "    s1sq = tf.square(dvar)\n",
    "    s2sq = tf.square(s2)\n",
    "    s3sq = tf.square(s3)\n",
    "    ang3 = np.arccos((-s3sq+s2sq+s1sq)/(2*dvar*s2))\n",
    "\n",
    "    #take third point of base triangle via distance * vector\n",
    "    v13 = tf.concat([tf.cos(ang3), tf.sin(ang3), tf.zeros_like(ang3)], axis=1)\n",
    "    p3 = s2*v13\n",
    "    #center points of 3rd sphere\n",
    "    ivar = tf.reshape(p3[:,0],(-1,1))\n",
    "    jvar = tf.reshape(p3[:,1],(-1,1))\n",
    "\n",
    "\n",
    "    #convert all to float32 to match generator output\n",
    "    #expand to dindex size \n",
    "\n",
    "    dvar = tf.cast(tf.repeat(dvar,dindex.shape[0],axis=1),dtype=tf.float32)\n",
    "    ivar = tf.cast(tf.repeat(ivar,dindex.shape[0],axis=1),dtype=tf.float32)\n",
    "    jvar = tf.cast(tf.repeat(jvar,dindex.shape[0],axis=1),dtype=tf.float32)\n",
    "    \n",
    "    return dvar, ivar, jvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function \n",
    "def train_step(input_z_var,ref_map_, helix_keep_mask_,\n",
    "               target_mp_, dvar_, ivar_, jvar_,\n",
    "                dMin_, mScale_, mMin_, dMin_nwp_, mScale_nwp_, \n",
    "                dindex_, pindex_, batch_,z_reflect_ind_, scale_):\n",
    "\n",
    "    with tf.GradientTape() as g_tape:\n",
    "        g_tape.watch(input_z_var)\n",
    "        g_o = gen_obj.g(input_z_var)\n",
    "        masked_loss = maskLoss(ref_map_, g_o, helix_keep_mask_)\n",
    "        mp_loss  = tf.divide(midpoints_loss(g_o, target_mp_, \n",
    "                    dvar_, ivar_, jvar_,\n",
    "                    dMin_, mScale_, mMin_, dMin_nwp_, mScale_nwp_, \n",
    "                    dindex_, pindex_, batch_,z_reflect_ind_), scale_)\n",
    "\n",
    "        loss = tf.reduce_sum(mp_loss,axis=1) + tf.reduce_sum(masked_loss,axis=1)\n",
    "\n",
    "    g_grads = g_tape.gradient(loss, input_z_var)\n",
    "    optimizer.apply_gradients(zip([g_grads],[input_z_var]))\n",
    "\n",
    "    return input_z_var, masked_loss, mp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def maskLoss(y_actual, y_pred,mask):\n",
    "    \"\"\"Loss Function for mantaing shape of input helices\"\"\"\n",
    "    custom_loss_val = tf.multiply(mask,tf.square(y_actual-y_pred))\n",
    "    return custom_loss_val\n",
    "\n",
    "@tf.function\n",
    "def midpoints_loss(g1, target, \n",
    "                   dvar, ivar, jvar,\n",
    "                   dMin, mScale, mMin, dMin_nwp, mScale_nwp, \n",
    "                   dindex, pindex, batch_size, zr_ind):\n",
    "    \"\"\"Loss function to move output of two generated helices to target midpoint\"\"\"\n",
    "\n",
    "\n",
    "    #now using dindex gather the desired indices for tetrahedron calcs\n",
    "\n",
    "    #radius of the spheres, aka the distances to unmasked endpoints\n",
    "    g2 = tf.gather(g1,dindex,axis=1)\n",
    "\n",
    "    #see https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler\n",
    "    #inspect .scale_\n",
    "    conv_dist = tf.add(tf.divide(tf.subtract(g2, mMin), mScale),dMin)\n",
    "    #transpose lets you easily grab all distances with gather/axis \n",
    "    conv_dist_squared = tf.transpose(tf.square(conv_dist),perm=[0, 2, 1]) \n",
    "\n",
    "    r1_sq = tf.gather(conv_dist_squared, 0, axis=1) \n",
    "    r2_sq =  tf.gather(conv_dist_squared,1, axis=1) \n",
    "    r3_sq = tf.gather(conv_dist_squared, 2, axis=1)\n",
    "\n",
    "    #calculate coordinates of spherial intersect\n",
    "    x = tf.divide(tf.add(tf.subtract(r1_sq,r2_sq),tf.square(dvar)),tf.multiply(2.0,dvar))\n",
    "    y1 = tf.divide(tf.add(tf.add(tf.subtract(r1_sq,r3_sq), tf.square(ivar)), tf.square(jvar)),tf.multiply(2.0,jvar))\n",
    "    y = tf.subtract(y1,tf.multiply(tf.divide(ivar,jvar),x))\n",
    "\n",
    "    pre_z = tf.subtract(tf.subtract(r1_sq,tf.square(x)),tf.square(y))\n",
    "    fixed_z = tf.clip_by_value(pre_z, 1e-10, 100)\n",
    "\n",
    "    #adds  to negative values to 0 for sqrt,\n",
    "    #I think is okay as zero z will imply lengthening of distances to match a non-zero target midpoint,\n",
    "    #pushing the network in the desired direction?\n",
    "\n",
    "    z = tf.sqrt(fixed_z) #assume positive solution\n",
    "    z_neg = tf.multiply(z,-1) #assume negative soluation\n",
    "\n",
    "    #new points, with both assumptions\n",
    "    nwp = tf.concat((tf.reshape(x,(batch_size,-1,1)),\n",
    "                    tf.reshape(y,(batch_size,-1,1)),\n",
    "                    tf.reshape(z,(batch_size,-1,1))), axis=2)  #\n",
    "\n",
    "    nwp_negz = tf.concat((tf.reshape(x,(batch_size,-1,1)),\n",
    "                    tf.reshape(y,(batch_size,-1,1)),\n",
    "                    tf.reshape(z_neg,(batch_size,-1,1))), axis=2)  #\n",
    "\n",
    "    #some positive solutions assumptions,\n",
    "    # assume first [i4] is actual positive use remaining distances of i4 to (i5,i6,i7) to determine z sign\n",
    "    # closest to matching distance is used\n",
    "\n",
    "\n",
    "    #let's start by calculating all i4 to (i5,i6,i7) distances\n",
    "\n",
    "    #stop the gradients since these are used to index gather and scatter\n",
    "    #unsqueeze at two different dimensionsq to broadcast into matrix MX1 by 1XN to MXN \n",
    "    nwp_p =  tf.stop_gradient(tf.expand_dims(nwp,axis=1) - tf.expand_dims(nwp,axis=2))\n",
    "    nwp_n =  tf.stop_gradient(tf.expand_dims(nwp,axis=1) - tf.expand_dims(nwp_negz,axis=2))\n",
    "\n",
    "    nwp_dist_pz = tf.reshape(tf.sqrt(tf.reduce_sum(tf.square(nwp_p), 3)),(-1,4,4)) #distance calc +1e6?\n",
    "    nwp_dist_nz = tf.reshape(tf.sqrt(tf.reduce_sum(tf.square(nwp_n), 3)),(-1,4,4))  #distance calc\n",
    "\n",
    "    z_pn_dist_pre_con = tf.gather(g1,pindex,axis=1)\n",
    "    z_pn_dist = tf.add(tf.divide(tf.subtract(z_pn_dist_pre_con, mMin), mScale_nwp),dMin_nwp)\n",
    "\n",
    "    #index p4 to p5,p6,p7\n",
    "    #rewrite as non-slice version of this\n",
    "\n",
    "    nwp_dist_pz_c = tf.squeeze(tf.gather(tf.gather(nwp_dist_pz, [0], axis=1), [1,2,3], axis=2))\n",
    "    nwp_dist_nz_c = tf.squeeze(tf.gather(tf.gather(nwp_dist_nz, [0], axis=1), [1,2,3], axis=2))\n",
    "\n",
    "    nwp_dist_pz_c = tf.expand_dims(nwp_dist_pz_c,axis=2)\n",
    "    nwp_dist_nz_c = tf.expand_dims(nwp_dist_nz_c,axis=2)\n",
    "\n",
    "    # #using a single distance decide the z assumption and apply\n",
    "    correct_z_assum = tf.abs(z_pn_dist - nwp_dist_nz_c) < tf.abs(z_pn_dist - nwp_dist_pz_c)\n",
    "    cz = tf.squeeze(tf.multiply(tf.cast(correct_z_assum,tf.int32),-2))\n",
    "\n",
    "    z_reflect_tensor = tf.ones_like(nwp, dtype=tf.int32)\n",
    "\n",
    "    nwp_mult = tf.cast(tf.tensor_scatter_nd_add(z_reflect_tensor, zr_ind, cz),dtype=tf.float32)\n",
    "    nwp_final = tf.multiply(nwp_mult,nwp)\n",
    "\n",
    "    midpoint = tf.reduce_mean(nwp_final,axis=1)\n",
    "    return tf.square(tf.subtract(midpoint,target)) # means squared loss to desired midpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullBUTT_GPU(gen_obj, ref_map, target_mp_in, batch_size=32,cycles=100, input_z=None, \n",
    "                          rate=0.05, target_ep=[4,5,6,7], num_helices=4, oneRef=True,\n",
    "                          scale=5.0, z_size=12):\n",
    "    \n",
    "    batch_indices = np.repeat(np.array(range(ref_map.shape[0])),batch_size)\n",
    "    batch = batch_indices.shape[0]\n",
    "    target_mp = tf.convert_to_tensor(np.repeat(target_mp_in, batch_size,axis=0),dtype=tf.float32)\n",
    "    ref_map = np.repeat(ref_map, batch_size, axis=0)\n",
    "    \n",
    "    #establish indices for distances to reference\n",
    "    #prep base triangle, convert distances from minmax to regular\n",
    "    dindex, base_tri = target_dindex(target_ep, oneRef = True, num_helices = num_helices)\n",
    "    base_tri = convert_dMat_to_iu1_index(base_tri) #dirty\n",
    "    pindex = point_dindex(target_ep[1:], ref=[target_ep[0]], num_helices = num_helices)\n",
    "\n",
    "    #convert generator output to 'real distances'\n",
    "    #dMin, mScale, mMin, dMin_nwp,  mScale_nwp = minMax_indices(dindex, pindex, brec.mm)\n",
    "    mmTuple = minMax_indices(dindex, pindex, gen_obj.mm)\n",
    "\n",
    "    # prepare base triangle for trilateriation (z plane , p1 at origin, p2 positive x)\n",
    "    #dvar, ivar, jvar = prep_base_triangle_trilateriation(dist[:batch], targ_dind = [4,5,6,7], oneRef = True, num_helices=4)\n",
    "    #baseTuple = prep_base_triangle_trilateriation(dist[:batch], targ_dind = target_ep, oneRef = True, num_helices=num_helices)\n",
    "\n",
    "    baseTuple = prep_base_triangle_trilateriation(dindex, base_tri, ref_map)\n",
    "    \n",
    "    dMin, mScale, mMin, dMin_nwp,  mScale_nwp = mmTuple\n",
    "    dvar,ivar,jvar = baseTuple\n",
    "    \n",
    "    #mask for keeping buttress helices in same orientation\n",
    "    h_index = helix_dindex([0,1], num_helices=4, intraHelixDist=True)\n",
    "    helix_keep_mask = np.zeros((ref_map.shape[1],),dtype=np.int32)\n",
    "    helix_keep_mask[h_index] = 1\n",
    "    helix_keep_mask = tf.convert_to_tensor(helix_keep_mask,dtype=tf.float32)\n",
    "\n",
    "    #input to generator (determinstic output)\n",
    "    \n",
    "    ref_map_conv = gen_obj.mm.transform(ref_map)\n",
    "    #controlling z reflection during trilaterization\n",
    "    z_r_innerInd = np.repeat(tf.convert_to_tensor([[[1,2],[2,2],[3,2]]]),batch,axis=0)\n",
    "    #batch index\n",
    "    zfi_bi =np.expand_dims(np.array(range(batch)).reshape((-1,1)).repeat(3,axis=1),axis=2)\n",
    "    z_reflect_ind = np.concatenate((zfi_bi,z_r_innerInd),axis=2)\n",
    "    \n",
    "    \n",
    "    if input_z is None:\n",
    "        input_z = tf.random.uniform(shape=(batch, z_size), minval=-1, maxval=1)\n",
    "        \n",
    "    with tf.device(device_name):\n",
    "        input_z_var = tf.Variable(input_z)\n",
    "        ref_map_ = tf.constant(ref_map_conv,dtype=tf.float32)\n",
    "        scale_, z_reflect_ind_ = tf.constant(scale), tf.constant(z_reflect_ind)\n",
    "        target_mp_, batch_ = tf.constant(target_mp),  tf.constant(batch)\n",
    "        dindex_, pindex_ = tf.constant(dindex), tf.constant(pindex)\n",
    "        dMin_, mScale_, mMin_ = tf.constant(dMin), tf.constant(mScale), tf.constant(mMin),\n",
    "        dMin_nwp_,  mScale_nwp_ =  tf.constant(dMin_nwp),  tf.constant(mScale_nwp)\n",
    "        dvar_, ivar_, jvar_ = tf.constant(dvar), tf.constant(ivar), tf.constant(jvar)\n",
    "        helix_keep_mask_ = tf.constant(helix_keep_mask, dtype=tf.float32)\n",
    "\n",
    "    #store grads and inputs as we backpropagate\n",
    "    z=[]\n",
    "    loss_mask = []\n",
    "    loss_mp = []\n",
    "    grads = []\n",
    "    \n",
    "\n",
    "\n",
    "    g_o = gen_obj.g(input_z_var)\n",
    "    masked_loss = maskLoss(ref_map_, g_o, helix_keep_mask_)\n",
    "    \n",
    "    mp_loss  = tf.divide(midpoints_loss(g_o, target_mp_, \n",
    "                        dvar_, ivar_, jvar_,\n",
    "                        dMin_, mScale_, mMin_, dMin_nwp_, mScale_nwp_, \n",
    "                        dindex_, pindex_, batch_, z_reflect_ind_), scale_)\n",
    "    print('start_masked',np.round(np.sum(masked_loss),2))\n",
    "    print('start_mp',np.round(np.sum(mp_loss),2))\n",
    "    \n",
    "    for t in range(1,cycles):\n",
    "        \n",
    "        in_z, mask_l, mp_l = train_step(input_z_var,ref_map_, helix_keep_mask_,\n",
    "                                        target_mp_, dvar_, ivar_, jvar_,\n",
    "                                        dMin_, mScale_, mMin_, dMin_nwp_, mScale_nwp_, \n",
    "                                        dindex_, pindex_, batch_, z_reflect_ind_, scale_)\n",
    "        \n",
    "        z.append(in_z.numpy())\n",
    "        loss_mask.append(mask_l.numpy())\n",
    "        loss_mp.append(mp_l.numpy())\n",
    "\n",
    "    print('end_masked', np.round(np.sum(loss_mask[-1]),2))\n",
    "    print('end_mp', np.round(np.sum(loss_mp[-1]),2))\n",
    "    \n",
    "    return z, loss_mask, loss_mp, batch_indices\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buttress_ep_from_z(gen_obj, gen_z, starting_ep , loss_midpoint, loss_masked, batchIndices,\n",
    "                       max_loss_mp = 0.001, max_loss_mask = 0.001):\n",
    "    \n",
    "    \n",
    "    best_mp = np.sum(loss_midpoint<max_loss_mp,axis=1)>2 # 3 total mp loss outputs (x,y,z of midpoint to target)\n",
    "    best_mask = np.sum(loss_masked<max_loss_mask,axis=1)>27 # 28 total mask loss point (2 helices)\n",
    "\n",
    "    mask_mp_bool = np.logical_and(best_mp, best_mask)       \n",
    "\n",
    "    identified_z = gen_z[mask_mp_bool]\n",
    "    print(f'Outputs passing filters: {len(identified_z)}')\n",
    "    print(f'Total Outputs: {len(gen_z)}')\n",
    "    uInd = batchIndices[mask_mp_bool]\n",
    "    \n",
    "    orig_ep = starting_ep[uInd]\n",
    "    \n",
    "    \n",
    "    gen_obj.generate(z=12, input_z = identified_z, batch_size=identified_z.shape[0])\n",
    "    gen_obj.MDS_reconstruct_()\n",
    "    \n",
    "    out_ep = np.array(gen_obj.reconsMDS_)\n",
    "    \n",
    "    return align_generated_to_starting_ep(out_ep, orig_ep)\n",
    "\n",
    "def buttress_ep_from_z_mask_only(gen_obj, gen_z,loss_masked, batchIndices,\n",
    "                                 max_loss_mask = 0.002, max_out=100, print_stats= False):\n",
    "    \n",
    "    \n",
    "    sm = np.sum(loss_masked,axis=1)\n",
    "    smi = np.argsort(sm)\n",
    "    sm_sort = sm[smi]\n",
    "    best_mask = sm_sort < max_loss_mask\n",
    "    \n",
    "    uInd = batchIndices[smi][best_mask]\n",
    "    \n",
    "    if print_stats:\n",
    "        print('Input Size: ',      len(sm))\n",
    "        print('Passing Filters: ', len(uInd))\n",
    "    \n",
    "    \n",
    "    if len(uInd)>max_out:\n",
    "        uInd = uInd[:max_out]\n",
    "    \n",
    "    identified_z = gen_z[uInd]\n",
    "    \n",
    "    gen_obj.generate(z=12, input_z = identified_z, batch_size=identified_z.shape[0])\n",
    "    gen_obj.MDS_reconstruct_()\n",
    "    \n",
    "    out_ep = np.array(gen_obj.reconsMDS_)\n",
    "    \n",
    "    return out_ep, uInd\n",
    "    \n",
    "    \n",
    "def align_generated_to_starting_ep(gen_ep, orig_ep, target_mp):\n",
    "    \"\"\"Uses Kabsh to align generated endpoints onto original endpoints. Orig_Ep on origin with oneRef.\"\"\"\n",
    "    #Thanks to below for this code; modified to batch form\n",
    "    #moves gen_\n",
    "    #https://pymolwiki.org/index.php/Kabsch\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    #only center on first four points [first two helices]\n",
    "    gen_ep_4 = gen_ep[:,:4,:].copy()\n",
    "    orig_ep_4 = orig_ep[:,:4,:].copy()\n",
    "    \n",
    "    \n",
    "    #centering to prevent affine transformaiton\n",
    "    COM_orig = np.expand_dims(np.sum(orig_ep_4, axis=1)/orig_ep_4.shape[1]   ,axis=1)\n",
    "    COM_gen =  np.expand_dims(np.sum(gen_ep_4,  axis=1)/gen_ep_4.shape[1]     ,axis=1)\n",
    "    \n",
    "    gen_ep_4_cen = gen_ep_4 - COM_gen\n",
    "    orig_ep_4_cen = orig_ep_4 - COM_orig\n",
    "    \n",
    "    #initial error estimate\n",
    "    #E0 = np.sum( np.sum(np.square(gen_ep_4),axis=1),axis=1) + np.sum( np.sum(np.square(orig_ep_4),axis=1),axis=1)\n",
    "\n",
    "    # This beautiful step provides the answer.  V and Wt are the orthonormal\n",
    "    # bases that when multiplied by each other give us the rotation matrix, U.\n",
    "    # S, (Sigma, from SVD) provides us with the error!  Isn't SVD great!                                            #2                      #1\n",
    "    V, S, Wt = np.linalg.svd( np.matmul(np.transpose(gen_ep_4_cen, axes=[0,2,1]), orig_ep_4_cen))\n",
    "\n",
    "    # we already have our solution, in the results from SVD.\n",
    "    # we just need to check for reflections and then produce\n",
    "    # the rotation.  V and Wt are orthonormal, so their det's\n",
    "    # are +/-1.\n",
    "    reflect = np.linalg.det(V) * np.linalg.det(Wt)\n",
    "    #original solution, I will take both reflections\n",
    "    #multiples by 1 or -1 depending if relfect is negative (reflection)\n",
    "    proper_reflection = ((reflect>0).astype(np.int32)*-2+1) \n",
    "    S[:,-1] = S[:,-1]*proper_reflection\n",
    "    V[:,:,-1] = -V[:,:,-1]*proper_reflection.reshape((-1,1))\n",
    "\n",
    "    V_reflect = V.copy()\n",
    "    V_reflect[:,:,-1] = -V_reflect[:,:,-1]\n",
    "    #Error\n",
    "#     RMSD = E0 - (2.0 * np.sum(S,axis=1))\n",
    "#     RMSD = np.sqrt(np.abs(RMSD / L))\n",
    "    \n",
    "    #generate rotation matrices\n",
    "    U = np.matmul(V, Wt)\n",
    "    U_reflect = np.matmul(V_reflect, Wt)\n",
    "\n",
    "#    return target_mp,COM_gen,COM_orig\n",
    "    final_target_midpoint = np.matmul(np.expand_dims((target_mp-COM_gen.squeeze(axis=1)),axis=1), U).squeeze() + COM_orig.squeeze(axis=1)\n",
    "    final_ep_full         = np.matmul((gen_ep-COM_gen), U) + COM_orig\n",
    "    final_ep_full_reflect = np.matmul((gen_ep-COM_gen), U_reflect) + COM_orig\n",
    "    \n",
    "    return final_ep_full, final_ep_full_reflect, final_target_midpoint\n",
    "\n",
    "def guess_reflection(p, p_reflect, des_mp, invert=False):\n",
    "    p_mp = get_midpoint(p, helices_desired=[2,3], num_helices=4)\n",
    "    p_reflect_mp = get_midpoint(p_reflect, helices_desired=[2,3], num_helices=4)\n",
    "    \n",
    "    final_ep = np.zeros_like(p)\n",
    "\n",
    "    measure1 = np.linalg.norm(p_mp - des_mp,axis=1)\n",
    "    measure2 =  np.linalg.norm(p_reflect_mp - des_mp,axis=1)\n",
    "\n",
    "    if not invert:\n",
    "        final_ep[np.nonzero((measure1<measure2))] = p[np.nonzero((measure1<measure2))]\n",
    "        final_ep[np.nonzero((measure1>measure2))] = p_reflect[np.nonzero((measure1>measure2))]\n",
    "    else:\n",
    "        final_ep[np.nonzero((measure1>measure2))] = p[np.nonzero((measure1>measure2))]\n",
    "        final_ep[np.nonzero((measure1<measure2))] = p_reflect[np.nonzero((measure1<measure2))]\n",
    "        \n",
    "    \n",
    "    return final_ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate array to hold endpoints\n",
    "batch=100\n",
    "mi = 0 #master index\n",
    "\n",
    "#random sample starting endpoints to buttress\n",
    "refi_all = list(range(ep_mp.shape[0]))\n",
    "ref_ind = np.array(random.sample(refi_all , batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 8, 3)\n",
      "start_masked 7820.83\n",
      "start_mp 11964.96\n",
      "end_masked 296.81\n",
      "end_mp 1840.66\n",
      "Input Size:  10000\n",
      "Passing Filters:  941\n"
     ]
    }
   ],
   "source": [
    "master_ep = ep_mp[ref_ind ,:4,...]\n",
    "    \n",
    "des_midpoint=[0,0,9]\n",
    "batch=100\n",
    "\n",
    "#second set of added points unused except for maintaining distance maps indexing from gen\n",
    "#(based around 4 helices)\n",
    "current_quad_prez = np.concatenate((master_ep[:,-4:,:],master_ep[:,-4:,:] ), axis=1)\n",
    "print(current_quad_prez.shape)\n",
    "\n",
    "#using just to keep mp reasonable\n",
    "current_quad = rotate_base_tri_Zplane(current_quad_prez,  target_point=4, index_mobile=[1,2,3])\n",
    "\n",
    "#find reasonable midpoint target to backprop from\n",
    "cq_mp = get_midpoint(current_quad, helices_desired=[0,1],num_helices=4)\n",
    "target_midpoint = cq_mp + des_midpoint\n",
    "\n",
    "#create distance map for generator\n",
    "start_dist = np.expand_dims(current_quad,axis=1) - np.expand_dims(current_quad,axis=2)\n",
    "dist = np.sqrt(np.sum(start_dist**2, 3))\n",
    "dist = dist.reshape((dist.shape[0],-1))\n",
    "\n",
    "#indices for reference map\n",
    "ref_map_base = ref_distmap_index(dist, num_helices=4)\n",
    "\n",
    "#GPU ##33s  with 500,000 samples with 200 cycles (average of 7 runs)\n",
    "#CPU ##39s\n",
    "#maybe there is something I can do to make this more effecient, not pipeline bottleneck so okay\n",
    "#for small models like this tensor flow says gpu may not be more effecient\n",
    "output_z, loss_mask, loss_mp, batchInd = fullBUTT_GPU(gen_obj, ref_map_base , target_midpoint, \n",
    "                                                    batch_size=100, cycles=200, input_z=None, \n",
    "                                                    rate=0.05, target_ep=[4,5,6,7], num_helices=4, \n",
    "                                                    oneRef=True, scale=100.0, z_size=12)\n",
    "\n",
    "\n",
    "out_ep, uInd =  buttress_ep_from_z_mask_only(gen_obj, output_z[-1], loss_mask[-1], batchInd,\n",
    "                                             max_out= 200,\n",
    "                                             max_loss_mask = 0.0005, print_stats= True)                       \n",
    "\n",
    "fa, fa_reflect, ftm = align_generated_to_starting_ep(out_ep, current_quad_prez[uInd], target_midpoint[uInd])\n",
    "final =guess_reflection(fa, fa_reflect, ftm)\n",
    "\n",
    "master_ep2 = np.concatenate((master_ep[uInd,:,:], final[:,4:,:]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = 3\n",
    "view_ep(current_quad_prez[uInd], name='cqpz_',max_out=mo)\n",
    "view_ep(fa, name='fa_',max_out=mo)\n",
    "view_ep(fa_reflect, name='fa_r_',max_out=mo)\n",
    "view_ep(master_ep2, name='mep2',max_out=mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 8, 3)\n",
      "start_masked 54854.2\n",
      "start_mp 18831.36\n",
      "end_masked 1926.66\n",
      "end_mp 5063.17\n",
      "Input Size:  20000\n",
      "Passing Filters:  379\n"
     ]
    }
   ],
   "source": [
    "des_midpoint=[0,0,9]\n",
    "batch=100\n",
    "\n",
    "#second set of added points unused except for maintaining distance maps indexing from gen\n",
    "#(based around 4 helices)\n",
    "current_quad_prez = np.concatenate((master_ep2[:,-4:,:],master_ep2[:,-4:,:] ), axis=1)\n",
    "print(current_quad_prez.shape)\n",
    "\n",
    "#using just to keep mp reasonable\n",
    "current_quad = rotate_base_tri_Zplane(current_quad_prez,  target_point=4, index_mobile=[1,2,3])\n",
    "\n",
    "#find reasonable midpoint target to backprop from\n",
    "cq_mp = get_midpoint(current_quad, helices_desired=[0,1],num_helices=4)\n",
    "target_midpoint = cq_mp + des_midpoint\n",
    "\n",
    "#create distance map for generator\n",
    "start_dist = np.expand_dims(current_quad,axis=1) - np.expand_dims(current_quad,axis=2)\n",
    "dist = np.sqrt(np.sum(start_dist**2, 3))\n",
    "dist = dist.reshape((dist.shape[0],-1))\n",
    "\n",
    "#indices for reference map\n",
    "ref_map_base = ref_distmap_index(dist, num_helices=4)\n",
    "\n",
    "#GPU ##33s  with 500,000 samples with 200 cycles (average of 7 runs)\n",
    "#CPU ##39s\n",
    "#maybe there is something I can do to make this more effecient, not pipeline bottleneck so okay\n",
    "#for small models like this tensor flow says gpu may not be more effecient\n",
    "output_z, loss_mask, loss_mp, batchInd = fullBUTT_GPU(gen_obj, ref_map_base , target_midpoint, \n",
    "                                                    batch_size=100, cycles=200, input_z=None, \n",
    "                                                    rate=0.05, target_ep=[4,5,6,7], num_helices=4, \n",
    "                                                    oneRef=True, scale=100.0, z_size=12)\n",
    "\n",
    "\n",
    "out_ep, uInd =  buttress_ep_from_z_mask_only(gen_obj, output_z[-1], loss_mask[-1], batchInd,\n",
    "                                             max_out= 200,\n",
    "                                             max_loss_mask = 0.0005, print_stats= True)\n",
    "        \n",
    "fa, fa_reflect, ftm = align_generated_to_starting_ep(out_ep, current_quad_prez[uInd], cq_mp)\n",
    "cq_mp2 = get_midpoint(master_ep2[uInd,-8:-4,:], helices_desired=[0,1],num_helices=4)\n",
    "\n",
    "final = guess_reflection(fa, fa_reflect, cq_mp2,invert=True)\n",
    "\n",
    "master_ep3 = np.concatenate((master_ep2[uInd,:,:], fa[:,4:,:]),axis=1)\n",
    "master_ep4 = np.concatenate((master_ep2[uInd,:,:], fa_reflect[:,4:,:]),axis=1)\n",
    "master_ep5 = np.concatenate((master_ep2[uInd,:,:], final[:,4:,:]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_ep(fa,name='fa',max_out=5)\n",
    "view_ep(fa_reflect,name='fa_reflect',max_out=5)\n",
    "view_ep(master_ep2[uInd,:,:],name='mep3',max_out=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_ep3 = np.concatenate((master_ep2[uInd,:,:], fa[:,4:,:]),axis=1)\n",
    "master_ep4 = np.concatenate((master_ep2[uInd,:,:], fa_reflect[:,4:,:]),axis=1)\n",
    "master_ep5 = np.concatenate((master_ep2[uInd,:,:], final[:,4:,:]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_ep(fa,name='fa',max_out=5)\n",
    "view_ep(fa_reflect,name='fa_reflect',max_out=5)\n",
    "view_ep(master_ep2[uInd,:,:],name='mep3',max_out=5)\n",
    "view_ep(master_ep5,name='mep5',max_out=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_mp =  cq_mp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mp = get_midpoint(fa, helices_desired=[2,3], num_helices=4)\n",
    "p_reflect_mp = get_midpoint(fa_reflect, helices_desired=[2,3], num_helices=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ep = np.zeros_like(fa)\n",
    "\n",
    "m1 = np.linalg.norm(p_mp - des_mp,axis=1)\n",
    "m2 =  np.linalg.norm(p_reflect_mp - des_mp,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.983684471315602"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.9836844713156"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.07, -0.17, 21.82])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_mp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29, 6.83, 2.12])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_reflect_mp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_reflection(p, p_reflect, des_mp, invert=False):\n",
    "    p_mp = get_midpoint(p, helices_desired=[2,3], num_helices=4)\n",
    "    p_reflect_mp = get_midpoint(p_reflect, helices_desired=[2,3], num_helices=4)\n",
    "    \n",
    "    final_ep = np.zeros_like(p)\n",
    "\n",
    "    measure1 = np.linalg.norm(p_mp - des_mp,axis=1)\n",
    "    measure2 =  np.linalg.norm(p_reflect_mp - des_mp,axis=1)\n",
    "\n",
    "    if not invert:\n",
    "        final_ep[np.nonzero((measure1<measure2))] = p[np.nonzero((measure1<measure2))]\n",
    "        final_ep[np.nonzero((measure1>measure2))] = p_reflect[np.nonzero((measure1>measure2))]\n",
    "    else:\n",
    "        final_ep[np.nonzero((measure1>measure2))] = p[np.nonzero((measure1>measure2))]\n",
    "        final_ep[np.nonzero((measure1<measure2))] = p_reflect[np.nonzero((measure1<measure2))]\n",
    "        \n",
    "    \n",
    "    return final_ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "final =guess_reflection(fa_reflect, fa, cq_mp2)\n",
    "master_ep3 = np.concatenate((master_ep2[uInd,:,:], final[:,4:,:]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_ep(master_ep3,name='mep4',max_out=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.76,  18.49,   8.11],\n",
       "       [  3.19,  20.2 ,   0.31],\n",
       "       [ -1.04,  18.34,   8.49],\n",
       "       [  7.49,  -0.59,  12.27],\n",
       "       [  3.64,  17.94,  -1.02],\n",
       "       [ -2.94,   4.53,  17.37],\n",
       "       [ -2.78,   4.11,  17.14],\n",
       "       [ 12.79,  10.89,  -3.17],\n",
       "       [ -1.04,  18.34,   8.49],\n",
       "       [  3.19,  20.2 ,   0.31],\n",
       "       [  4.39,  16.78,  -5.15],\n",
       "       [ -7.78,  10.99,  15.01],\n",
       "       [ -2.97,   1.56,  13.97],\n",
       "       [ -1.15,  18.35,   8.75],\n",
       "       [ -0.76,  18.49,   8.11],\n",
       "       [  3.91,  17.89,  -1.16],\n",
       "       [ -1.05,  18.32,   8.5 ],\n",
       "       [ -2.97,   4.6 ,  17.38],\n",
       "       [  3.19,  20.2 ,   0.31],\n",
       "       [ -2.69,   3.86,  17.17],\n",
       "       [  4.33,  16.67,  -5.12],\n",
       "       [  3.19,  20.2 ,   0.31],\n",
       "       [  3.33,  18.58,  -0.24],\n",
       "       [ -0.29,  17.7 ,  -4.47],\n",
       "       [  8.8 ,   0.41,   2.62],\n",
       "       [  4.41,  16.58,  -5.14],\n",
       "       [ -2.96,   4.58,  17.37],\n",
       "       [ -2.96,   4.58,  17.37],\n",
       "       [  3.64,  17.94,  -1.02],\n",
       "       [ -7.49,  15.14,   9.24],\n",
       "       [ -3.39,   1.55,  14.14],\n",
       "       [  4.48,  16.59,  -5.09],\n",
       "       [ -0.84,  18.5 ,   8.2 ],\n",
       "       [  9.89,   1.58,  -0.77],\n",
       "       [ 12.  ,   2.28,  -7.66],\n",
       "       [ 13.23,   9.79,  -2.49],\n",
       "       [ -7.04,  15.84,  -0.75],\n",
       "       [ -6.12,   9.31,  11.13],\n",
       "       [ -5.35,  14.15,   1.26],\n",
       "       [  3.91,  17.89,  -1.16],\n",
       "       [ -7.78,  10.99,  15.01],\n",
       "       [  7.49,  -0.59,  12.27],\n",
       "       [  8.63,  12.46,  -1.88],\n",
       "       [ -6.77,  15.81,  -0.81],\n",
       "       [  9.83,   5.72, -12.95],\n",
       "       [ -1.02,  18.4 ,   8.42],\n",
       "       [ -7.61,  14.98,   9.89],\n",
       "       [ -7.49,  15.14,   9.24],\n",
       "       [ 12.  ,   2.28,  -7.66],\n",
       "       [  9.89,   1.58,  -0.71],\n",
       "       [  9.76,   5.87, -13.  ],\n",
       "       [  9.89,   1.58,  -0.77],\n",
       "       [ -2.65,   3.83,  17.16],\n",
       "       [ -3.39,   1.55,  14.14],\n",
       "       [  3.89,   0.92,  12.43],\n",
       "       [ -1.15,  18.35,   8.75],\n",
       "       [ -5.35,  14.15,   1.26],\n",
       "       [  3.89,   0.93,  12.42],\n",
       "       [  3.19,  20.2 ,   0.31],\n",
       "       [ -7.04,  15.84,  -0.75],\n",
       "       [  4.48,  16.59,  -5.09],\n",
       "       [ -1.02,  18.4 ,   8.42],\n",
       "       [  3.19,  20.2 ,   0.31],\n",
       "       [  4.39,  16.78,  -5.15],\n",
       "       [  4.33,  16.67,  -5.12],\n",
       "       [  0.69,   3.39,  17.87],\n",
       "       [  3.19,  20.2 ,   0.31],\n",
       "       [ -1.42,  13.76,   4.62],\n",
       "       [ -5.38,  13.71,  -3.25],\n",
       "       [ -1.05,  18.32,   8.5 ],\n",
       "       [ -7.04,  15.84,  -0.75],\n",
       "       [ -6.77,  15.81,  -0.81],\n",
       "       [ -5.38,  13.71,  -3.25],\n",
       "       [  3.91,  17.89,  -1.16],\n",
       "       [ 12.3 ,  -4.11,  -1.79],\n",
       "       [ -8.32,   5.39,   7.51],\n",
       "       [ -0.84,  18.5 ,   8.2 ],\n",
       "       [  3.89,   0.92,  12.43],\n",
       "       [ -9.36,  12.23,   2.34],\n",
       "       [ -1.27,  17.49,  -4.08],\n",
       "       [ -4.43,   6.59,  11.31],\n",
       "       [ -6.12,   9.31,  11.13],\n",
       "       [  4.41,  16.58,  -5.14],\n",
       "       [ -2.96,   4.58,  17.37],\n",
       "       [  1.97,  15.64,  -2.98],\n",
       "       [ -1.05,  18.32,   8.5 ],\n",
       "       [ -9.36,  12.23,   2.34],\n",
       "       [ -2.97,   1.56,  13.97],\n",
       "       [  9.09,   2.38,   0.25],\n",
       "       [  4.48,  16.59,  -5.09],\n",
       "       [ -2.97,   1.56,  13.97],\n",
       "       [  4.39,  16.78,  -5.15],\n",
       "       [  3.89,   0.93,  12.42],\n",
       "       [  4.33,  16.67,  -5.12],\n",
       "       [ -7.04,  15.84,  -0.75],\n",
       "       [  3.89,   0.92,  12.43],\n",
       "       [ -2.97,   4.6 ,  17.38],\n",
       "       [  9.53,   2.57,  -0.15],\n",
       "       [  7.49,  -0.59,  12.27],\n",
       "       [  7.45,   4.8 ,  15.06],\n",
       "       [ 12.  ,   2.28,  -7.66],\n",
       "       [  4.33,  16.67,  -5.12],\n",
       "       [ -7.49,  15.14,   9.24],\n",
       "       [ 13.11,   9.99,  -2.63],\n",
       "       [ 12.  ,   2.28,  -7.66],\n",
       "       [ -1.14,  17.5 ,  -4.14],\n",
       "       [  4.39,  16.78,  -5.15],\n",
       "       [  4.33,  16.67,  -5.12],\n",
       "       [  3.33,  18.58,  -0.24],\n",
       "       [ -3.03,   1.43,  14.06],\n",
       "       [ -9.36,  12.23,   2.34],\n",
       "       [ 12.3 ,  -4.11,  -1.79],\n",
       "       [  4.33,  16.67,  -5.12],\n",
       "       [  2.76,  14.86,   1.35],\n",
       "       [ -3.39,   1.55,  14.14],\n",
       "       [ -7.61,  14.98,   9.89],\n",
       "       [ -0.84,  18.5 ,   8.2 ],\n",
       "       [  7.49,  -0.59,  12.27],\n",
       "       [  7.49,  -0.59,  12.27],\n",
       "       [ -5.38,  13.71,  -3.25],\n",
       "       [  7.45,   4.8 ,  15.06],\n",
       "       [ 12.  ,   2.28,  -7.66],\n",
       "       [ -2.97,   4.6 ,  17.38],\n",
       "       [ -2.97,   1.56,  13.97],\n",
       "       [ -2.97,   4.6 ,  17.38],\n",
       "       [  3.89,   0.93,  12.42],\n",
       "       [ 13.23,   9.79,  -2.49],\n",
       "       [ -2.92,   4.49,  17.37],\n",
       "       [ -1.04,  18.34,   8.49],\n",
       "       [ -7.74,   9.36,  12.51],\n",
       "       [  3.89,   0.93,  12.42],\n",
       "       [ -4.44,   6.48,  11.32],\n",
       "       [ -5.35,  14.15,   1.26],\n",
       "       [  4.48,  16.59,  -5.09],\n",
       "       [ -7.49,  15.14,   9.24],\n",
       "       [  1.72,  -1.46,  11.38],\n",
       "       [ -9.36,  12.23,   2.34],\n",
       "       [ -2.97,   4.6 ,  17.38],\n",
       "       [  4.41,  16.58,  -5.14],\n",
       "       [ -9.36,  12.23,   2.34],\n",
       "       [ 12.  ,   2.28,  -7.66],\n",
       "       [  0.69,   3.39,  17.87],\n",
       "       [ 12.  ,   2.28,  -7.66],\n",
       "       [ 11.77,   6.  ,   3.02],\n",
       "       [  7.45,   4.8 ,  15.06],\n",
       "       [ -9.36,  12.23,   2.34],\n",
       "       [ -7.78,  10.99,  15.01],\n",
       "       [  4.39,  16.78,  -5.15],\n",
       "       [  4.41,  16.58,  -5.14],\n",
       "       [ -7.74,   9.36,  12.51],\n",
       "       [  2.06,  15.6 ,  -2.94],\n",
       "       [  9.89,   1.58,  -0.71],\n",
       "       [ -3.03,   1.43,  14.06],\n",
       "       [  3.33,  18.58,  -0.24],\n",
       "       [ 11.64,  -0.91,  -4.3 ],\n",
       "       [  4.39,  16.78,  -5.15],\n",
       "       [  4.41,  16.58,  -5.14],\n",
       "       [  1.97,  15.64,  -2.98],\n",
       "       [  7.49,  -0.59,  12.27],\n",
       "       [  3.89,   0.93,  12.42],\n",
       "       [  4.41,  16.58,  -5.14],\n",
       "       [  4.48,  16.59,  -5.09],\n",
       "       [ -9.07,  12.4 ,   2.  ],\n",
       "       [ -2.97,   1.56,  13.97],\n",
       "       [ -9.07,  12.4 ,   2.  ],\n",
       "       [  3.89,   0.93,  12.42],\n",
       "       [ -5.38,  13.71,  -3.25],\n",
       "       [ -5.38,  13.71,  -3.25],\n",
       "       [ -0.77,  18.52,   8.16],\n",
       "       [  3.89,   0.93,  12.42],\n",
       "       [  1.97,  15.64,  -2.98],\n",
       "       [ -4.44,   6.48,  11.32],\n",
       "       [ 13.25,   9.79,  -2.47],\n",
       "       [ -3.03,   1.43,  14.06],\n",
       "       [ -5.46,  13.79,   4.36],\n",
       "       [  8.63,  12.46,  -1.88],\n",
       "       [ -5.35,  14.15,   1.26],\n",
       "       [  4.39,  16.78,  -5.15],\n",
       "       [  3.33,  18.58,  -0.24],\n",
       "       [ -3.39,   1.55,  14.14],\n",
       "       [  2.06,  15.6 ,  -2.94],\n",
       "       [  3.89,   0.93,  12.42],\n",
       "       [ -5.38,  13.71,  -3.25],\n",
       "       [  9.89,   1.58,  -0.77],\n",
       "       [  7.49,  -0.59,  12.27],\n",
       "       [  9.89,   1.58,  -0.71],\n",
       "       [ -0.92,  17.53,  -4.23],\n",
       "       [  4.41,  16.58,  -5.14],\n",
       "       [ -5.38,  13.71,  -3.25],\n",
       "       [  3.89,   0.93,  12.42],\n",
       "       [  8.8 ,   0.41,   2.62],\n",
       "       [ -5.38,  13.71,  -3.25],\n",
       "       [ 12.  ,   2.28,  -7.66],\n",
       "       [  3.89,   0.92,  12.43],\n",
       "       [ -8.47,  10.05,   2.31],\n",
       "       [  3.89,   0.92,  12.43],\n",
       "       [ -6.99,   8.71,  12.91],\n",
       "       [ -5.38,  13.71,  -3.25],\n",
       "       [  2.76,  14.86,   1.35],\n",
       "       [ -2.92,   4.49,  17.37]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cq_mp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ep_z = rotate_base_tri_Zplane(out_ep,  target_point=4, index_mobile=[1,2,3])\n",
    "cq_mp = get_midpoint(out_ep_z, helices_desired=[0,1],num_helices=4)\n",
    "target_midpoint = cq_mp + des_midpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_ep(np.expand_dims(cq_mp,axis=1), name= 'cq_mp', max_out=mo)\n",
    "view_ep(np.expand_dims(target_midpoint,axis=1), name= 'tgmp', max_out=mo)\n",
    "view_ep(out_ep_z, name= 'oepz', max_out=mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo=2\n",
    "view_ep(np.expand_dims(target_midpoint[uInd],axis=1), name= 't1p', max_out = mo)\n",
    "#view_ep(out_ep, name= 't2p', max_out=5)\n",
    "view_ep(out_ep_z, name= 't3p', max_out=mo)\n",
    "view_ep(np.expand_dims(cq_mp,axis=1), name= 't4p', max_out=mo)\n",
    "view_ep(fa, name= 't5p', max_out=mo)\n",
    "view_ep(fa_reflect, name= 't6p', max_out=mo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_ep(final, name= 't7p', max_out=mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(target_midpoint[uInd],axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 8, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_ep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa, fa_reflect, ftm = align_generated_to_starting_ep(out_ep, current_quad_prez[uInd], target_midpoint[uInd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = guess_reflection(fa, fa_reflect, ftm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.53,  2.62,  3.54],\n",
       "       [11.54, 15.8 , 10.51],\n",
       "       [ 6.96, 22.83, 12.08],\n",
       "       [-9.56, 11.3 ,  1.45],\n",
       "       [-5.64, 16.62, -7.52],\n",
       "       [ 8.56, 27.68,  4.12],\n",
       "       [15.46, 18.07, -5.43],\n",
       "       [ 2.8 , 10.05,  0.94]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_ep2 = np.concatenate((master_ep[uInd,:,:], final[:,4:,:]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_ep(fa, name= 't1')\n",
    "view_ep(current_quad_prez[uInd], name= 't2')\n",
    "view_ep(master_ep2 , name= 't3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf.HelicalProtein.makePointPDB(master_ep[uInd][0],f't1.pdb',outDirec='output/')\n",
    "hf.HelicalProtein.makePointPDB(fa[0],f't2.pdb',outDirec='output/')\n",
    "hf.HelicalProtein.makePointPDB(master_ep2[0],f't3.pdb',outDirec='output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.03,   2.8 ,   1.25],\n",
       "       [ 11.69,  16.55,  13.98],\n",
       "       [  8.39,  23.07,   9.85],\n",
       "       [-10.65,  10.13,   2.51],\n",
       "       [  0.  ,   0.  ,   0.  ],\n",
       "       [  0.  ,   0.  ,   0.  ],\n",
       "       [  0.  ,   0.  ,   0.  ],\n",
       "       [  0.  ,   0.  ,   0.  ]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_ep2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = fa\n",
    "p_reflect = fa_reflect\n",
    "des_mp = ftm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mp = get_midpoint(p, helices_desired=[2,3], num_helices=4)\n",
    "p_reflect_mp = get_midpoint(p_reflect, helices_desired=[2,3], num_helices=4)\n",
    "\n",
    "final_ep = np.zeros_like(p)\n",
    "\n",
    "measure1 = np.linalg.norm(p_mp - des_mp,axis=1)\n",
    "measure2 =  np.linalg.norm(p_reflect_mp - des_mp,axis=1)\n",
    "\n",
    "final_ep[np.nonzero((measure1<measure2))] = p[np.nonzero(measure1<measure2)]\n",
    "final_ep[np.nonzero((measure1>measure2))] = p_reflect[np.nonzero((measure1>measure2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_mp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 3)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des_mp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(measure1<measure2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   0,   1,   1,   1,   2,   3,   4,   4,   4,   5,   6,   6,\n",
       "          7,   7,   8,   8,   8,   9,   9,   9,  10,  11,  11,  12,  13,\n",
       "         13,  14,  14,  14,  15,  16,  17,  18,  18,  19,  19,  20,  21,\n",
       "         21,  21,  22,  23,  24,  25,  25,  26,  26,  26,  27,  27,  28,\n",
       "         29,  29,  30,  30,  31,  31,  32,  32,  32,  33,  33,  34,  35,\n",
       "         36,  37,  37,  38,  38,  38,  39,  40,  41,  41,  42,  42,  43,\n",
       "         43,  44,  45,  45,  46,  46,  47,  47,  48,  48,  49,  49,  50,\n",
       "         50,  51,  51,  52,  52,  53,  54,  54,  55,  56,  56,  56,  57,\n",
       "         58,  59,  59,  59,  60,  60,  60,  61,  61,  62,  62,  63,  64,\n",
       "         64,  64,  65,  65,  66,  66,  67,  67,  68,  69,  70,  70,  71,\n",
       "         71,  71,  72,  73,  73,  74,  75,  75,  76,  76,  77,  77,  78,\n",
       "         79,  80,  80,  81,  82,  82,  83,  83,  84,  84,  85,  86,  87,\n",
       "         87,  88,  89,  90,  91,  91,  92,  92,  93,  93,  93,  94,  94,\n",
       "         94,  95,  95,  96,  96,  97,  97,  97,  98,  98,  99,  99,  99,\n",
       "        100, 100, 100, 101, 102, 103, 103, 104, 104, 105, 105, 105, 106,\n",
       "        106, 107, 107, 107, 108, 108, 109, 109, 110, 110, 111, 112, 113,\n",
       "        114, 115, 115, 116, 116, 117, 118, 119, 119, 120, 120, 120, 121,\n",
       "        122, 122, 123, 123, 123, 124, 125, 126, 126, 126, 127, 127, 128,\n",
       "        128, 129, 129, 129, 130, 130, 131, 131, 132, 133, 134, 135, 136,\n",
       "        137, 137, 138, 139, 139, 140, 141, 141, 142, 142, 142, 143, 143,\n",
       "        143, 144, 145, 145, 146, 147, 147, 147, 148, 149, 149, 149, 150,\n",
       "        151, 151, 152, 153, 154, 154, 155, 155, 156, 156, 156, 157, 158,\n",
       "        158, 158, 159, 159, 159, 160, 161, 162, 162, 163, 163, 164, 164,\n",
       "        165, 165, 166, 167, 167, 168, 168, 169, 170, 171, 171, 171, 172,\n",
       "        173, 174, 174, 175, 175, 176, 177, 177, 178, 178, 178, 179, 179,\n",
       "        179, 180, 181, 181, 182, 182, 183, 184, 184, 185, 185, 185, 186,\n",
       "        186, 186, 187, 187, 188, 188, 188, 189, 189, 190, 190, 191, 191,\n",
       "        192, 192, 193, 193, 194, 195, 195, 196, 196, 197, 197, 198, 198,\n",
       "        199], dtype=int64),\n",
       " array([0, 2, 0, 1, 2, 2, 2, 0, 1, 2, 2, 1, 2, 0, 2, 0, 1, 2, 0, 1, 2, 2,\n",
       "        1, 2, 2, 0, 2, 0, 1, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2,\n",
       "        0, 2, 0, 1, 2, 0, 2, 2, 0, 2, 1, 2, 0, 2, 0, 1, 2, 0, 2, 2, 2, 2,\n",
       "        1, 2, 0, 1, 2, 2, 2, 0, 2, 0, 2, 1, 2, 2, 0, 2, 0, 2, 0, 2, 1, 2,\n",
       "        0, 2, 1, 2, 0, 2, 0, 2, 2, 1, 2, 2, 0, 1, 2, 2, 2, 0, 1, 2, 0, 1,\n",
       "        2, 0, 2, 0, 2, 2, 0, 1, 2, 0, 2, 1, 2, 0, 2, 2, 2, 0, 2, 0, 1, 2,\n",
       "        2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 1, 2, 0, 2, 2,\n",
       "        2, 0, 2, 2, 2, 2, 1, 2, 0, 2, 0, 1, 2, 0, 1, 2, 0, 2, 0, 2, 0, 1,\n",
       "        2, 1, 2, 0, 1, 2, 0, 1, 2, 2, 2, 1, 2, 1, 2, 0, 1, 2, 0, 2, 0, 1,\n",
       "        2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 1, 2,\n",
       "        2, 0, 2, 0, 1, 2, 2, 2, 0, 1, 2, 0, 2, 1, 2, 0, 1, 2, 1, 2, 0, 2,\n",
       "        2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 1, 2, 0, 1, 2, 2, 0, 2,\n",
       "        2, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 1, 2, 2, 0,\n",
       "        1, 2, 0, 1, 2, 2, 2, 0, 2, 0, 2, 0, 2, 1, 2, 2, 0, 2, 0, 2, 2, 2,\n",
       "        0, 1, 2, 2, 2, 0, 2, 1, 2, 2, 0, 2, 0, 1, 2, 0, 1, 2, 2, 0, 2, 0,\n",
       "        2, 2, 0, 2, 0, 1, 2, 0, 1, 2, 0, 2, 0, 1, 2, 0, 2, 0, 2, 0, 2, 0,\n",
       "        2, 0, 2, 2, 0, 2, 1, 2, 1, 2, 0, 2, 2], dtype=int64))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(measure1<measure2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_reflection(p, p_reflect, des_mp):\n",
    "    p_mp = get_midpoint(p, helices_desired=[2,3], num_helices=4)\n",
    "    p_reflect_mp = get_midpoint(p_reflect, helices_desired=[2,3], num_helices=4)\n",
    "    \n",
    "    final_ep = np.zeros_like(p)\n",
    "\n",
    "    measure1 = np.linalg.norm(p_mp - des_mp,axis=1)\n",
    "    measure2 =  np.linalg.norm(p_reflect_mp - des_mp,axis=1)\n",
    "\n",
    "    final_ep[np.nonzero((measure1<measure2))] = p[np.nonzero((measure1<measure2))]\n",
    "    final_ep[np.nonzero((measure1>measure2))] = p_reflect[np.nonzero((measure1>measure2))]\n",
    "    \n",
    "    return final_ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device name CPU\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#prep endpoint dataset for use with easy use with Trilateration:\n",
    "#Essentially identify 3 points on 1st two helices (Rotate/Translate to Z-plane) with \n",
    "#index mobile 1 at 0,0,0, target point in the positive z (trilateration assumtion)\n",
    "#roughly 10% of z values of helices 3/4 are in the negative feild, with point enforced 4 positive\n",
    "\n",
    "#distance map of ep dataset\n",
    "#unsqueeze at two different dimensionsq to broadcast into matrix MX1 by 1XN to MXN \n",
    "dX = np.expand_dims(X,axis=1) - np.expand_dims(X,axis=2)\n",
    "dist = np.sqrt(np.sum(dX**2, 3))  #+ 1e-6) #this dataset is good \n",
    "dist = dist.reshape((dist.shape[0],-1))\n",
    "\n",
    "mp_01 = get_midpoint(X,helices_desired=[0,1])\n",
    "mp_23 = get_midpoint(X,helices_desired=[2,3])\n",
    "# d= np.linalg.norm(mp_02-mp_01,axis=1)\n",
    "# sns.histplot(d)\n",
    "\n",
    "#mp distance map\n",
    "ep_mp = np.hstack((X.reshape((-1,24)),mp_01,mp_23)).reshape(-1,10,3) #helix12mp=8  helix34mp=9\n",
    "#unsqueeze at two different dimensionsq to broadcast into matrix MX1 by 1XN to MXN \n",
    "dep_mp = np.expand_dims(ep_mp,axis=1) - np.expand_dims(ep_mp,axis=2)\n",
    "dist_mp = np.sqrt(np.sum(dep_mp**2, 3))  #+ 1e-6) #this dataset is good \n",
    "dist_mp = dist_mp.reshape((dist_mp.shape[0],-1))\n",
    "\n",
    "\n",
    "zp_ep_mp = rotate_base_tri_Zplane(ep_mp,  target_point=4, index_mobile=[1,2,3])\n",
    "\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    device_name = tf.test.gpu_device_name()\n",
    "else:\n",
    "    device_name = 'CPU'\n",
    "#device_name = 'GPU' \n",
    "print(f'device name {device_name}')\n",
    "\n",
    "gen=\"data/BestGenerator\"\n",
    "rate =0.05\n",
    "\n",
    "with tf.device(device_name):\n",
    "    gen_obj = ge.BatchRecon(gen)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=rate)\n",
    "output1=gen_obj.generate(z=12,batch_size=12) #example generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_butts(gen_obj, initial_ep, additions=3, des_midpoint=[0,0,9], batch=100):\n",
    "    \"\"\"No selection based on how well the backprop against the mp went. but useful to test\"\"\"\n",
    "    \n",
    "    master_ep = initial_ep[:,:4,...]# if there are more than 4ep (2 helices) just take the first two\n",
    "    \n",
    "    for mi in range(additions):\n",
    "    \n",
    "        #second set of added points unused except for maintaining distance maps indexing from gen\n",
    "        #(based around 4 helices)\n",
    "        current_quad_prez = np.concatenate((master_ep[:,-4:,:],master_ep[:,-4:,:] ), axis=1)\n",
    "        print(current_quad_prez.shape)\n",
    "\n",
    "        #using just to keep mp reasonable\n",
    "        current_quad = rotate_base_tri_Zplane(current_quad_prez,  target_point=4, index_mobile=[1,2,3])\n",
    "\n",
    "        #find reasonable midpoint target to backprop from\n",
    "        cq_mp = get_midpoint(current_quad, helices_desired=[0,1],num_helices=4)\n",
    "        target_midpoint = cq_mp + des_midpoint\n",
    "\n",
    "        #create distance map for generator\n",
    "        start_dist = np.expand_dims(current_quad,axis=1) - np.expand_dims(current_quad,axis=2)\n",
    "        dist = np.sqrt(np.sum(start_dist**2, 3))\n",
    "        dist = dist.reshape((dist.shape[0],-1))\n",
    "\n",
    "        #indices for reference map\n",
    "        ref_map_base = ref_distmap_index(dist, num_helices=4)\n",
    "\n",
    "        #GPU ##33s  with 500,000 samples with 200 cycles (average of 7 runs)\n",
    "        #CPU ##39s\n",
    "        #maybe there is something I can do to make this more effecient, not pipeline bottleneck so okay\n",
    "        #for small models like this tensor flow says gpu may not be more effecient\n",
    "        output_z, loss_mask, loss_mp, batchInd = fullBUTT_GPU(gen_obj, ref_map_base , target_midpoint, \n",
    "                                                            batch_size=100, cycles=200, input_z=None, \n",
    "                                                            rate=0.05, target_ep=[4,5,6,7], num_helices=4, \n",
    "                                                            oneRef=True, scale=100.0, z_size=12)\n",
    "\n",
    "\n",
    "        out_ep, uInd =  buttress_ep_from_z_mask_only(gen_obj, output_z[-1], loss_mask[-1], batchInd,\n",
    "                                                     max_out= 200,\n",
    "                                                     max_loss_mask = 0.0005, print_stats= True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        out_ep_z = rotate_base_tri_Zplane(out_ep,  target_point=4, index_mobile=[1,2,3])\n",
    "        out_ep_zmp = get_midpoint(out_ep_z, helices_desired=[0,1],num_helices=4)\n",
    "        out_tmp = des_midpoint + out_ep_zmp\n",
    "        \n",
    "        fa, fa_reflect, ftm = align_generated_to_starting_ep(out_ep_z, current_quad_prez[uInd], out_tmp)\n",
    "        \n",
    "        if mi>0:\n",
    "            #make sure the reflection is opposite the previous buttress\n",
    "            cq_mp2 = get_midpoint(master_ep[uInd,-8:-4,:], helices_desired=[0,1],num_helices=4)\n",
    "        else:\n",
    "            cq_mp2 = get_midpoint(master_ep[uInd,:4,:], helices_desired=[0,1],num_helices=4)+0.01\n",
    "            \n",
    "            \n",
    "        \n",
    "        #keep away from input midpoint instead of close too\n",
    "        final = guess_reflection(fa, fa_reflect, cq_mp2,invert=True)\n",
    "        \n",
    "        #concatenate on new helix pair to master ep and repeat\n",
    "        master_ep = np.concatenate((master_ep[uInd,:,:], final[:,4:,:]),axis=1)\n",
    "    \n",
    "    \n",
    "    return master_ep\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 8, 3)\n",
      "start_masked 7723.98\n",
      "start_mp 10606.22\n",
      "end_masked 248.72\n",
      "end_mp 1208.56\n",
      "Input Size:  10000\n",
      "Passing Filters:  2223\n",
      "(200, 8, 3)\n",
      "start_masked 67405.68\n",
      "start_mp 20916.68\n",
      "end_masked 3151.32\n",
      "end_mp 6004.82\n",
      "Input Size:  20000\n",
      "Passing Filters:  234\n",
      "(200, 8, 3)\n",
      "start_masked 71784.74\n",
      "start_mp 30026.1\n",
      "end_masked 3568.82\n",
      "end_mp 11970.73\n",
      "Input Size:  20000\n",
      "Passing Filters:  660\n"
     ]
    }
   ],
   "source": [
    "butss = random_butts(gen_obj, ep_mp[ref_ind ,:4,...], additions=3, des_midpoint=[0,0,8], batch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_ep(butss, name='test', max_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf.HelicalProtein.makePointPDB(butss[0],f't1.pdb',outDirec='output/')\n",
    "hf.HelicalProtein.makePointPDB(butss[1],f't2.pdb',outDirec='output/')\n",
    "hf.HelicalProtein.makePointPDB(butss[2],f't3.pdb',outDirec='output/')\n",
    "#hf.HelicalProtein.makePointPDB(butss[3],f't4.pdb',outDirec='output/')\n",
    "#hf.HelicalProtein.makePointPDB(butss[4],f't5.pdb',outDirec='output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_ep(ep_in, name='test', max_out=10):\n",
    "    \n",
    "    outDirec='output/'\n",
    "    \n",
    "    if len(ep_in)>max_out:\n",
    "        it = max_out\n",
    "    else:\n",
    "        it = len(ep_in)\n",
    "    \n",
    "    for i in range(it):\n",
    "        hf.HelicalProtein.makePointPDB(ep_in[i], f'{name}{i}.pdb', outDirec='output/')\n",
    "        \n",
    "    cmd.delete(\"all\")\n",
    "    for i in range(it):\n",
    "        cmd.load(f'{outDirec}/{name}{i}.pdb')\n",
    "        \n",
    "    \n",
    "    cmd.save(f'{outDirec}/viewEP_{name}.pse')\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate array to hold endpoints\n",
    "batch=100\n",
    "mi = 0 #master index\n",
    "\n",
    "#random sample starting endpoints to buttress\n",
    "refi_all = list(range(ep_mp.shape[0]))\n",
    "ref_ind = np.array(random.sample(refi_all , batch))\n",
    "\n",
    "#master_ep contains endpoints in original coordinates space\n",
    "master_ep = ep_mp[ref_ind ,:4,...]\n",
    "\n",
    "#starting concat special to orient points with original, helices to intialize directionality of addition (z refelect)\n",
    "#points unused except for this orientation step and maintaining distance maps indexing\n",
    "current_quad_prez = np.concatenate((ep_mp[ref_ind ,:4,...], ep_mp[ref_ind ,4:8,...]), axis=1)\n",
    "\n",
    "current_quad = rotate_base_tri_Zplane(current_quad_prez,  target_point=4, index_mobile=[1,2,3])\n",
    "\n",
    "#find reasonable midpoint target to backprop from\n",
    "cq_mp = get_midpoint(current_quad, helices_desired=[0,1],num_helices=4)\n",
    "target_midpoint = cq_mp + np.array([[0,0,9]])\n",
    "start_dist = np.expand_dims(current_quad,axis=1) - np.expand_dims(current_quad,axis=2)\n",
    "dist = np.sqrt(np.sum(start_dist**2, 3))\n",
    "dist = dist.reshape((dist.shape[0],-1))\n",
    "\n",
    "#will need to add method to convert helix 1,2,3,4 to just helix 1,2 (remove 1,2 convert 3,4 to )\n",
    "ref_map_base = ref_distmap_index(dist, num_helices=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_masked 8074.31\n",
      "start_mp 10364.16\n",
      "end_masked 213.91\n",
      "end_mp 991.99\n",
      "Wall time: 3.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#GPU ##33s  with 10*50000 start with 200 cycles\n",
    "#CPU ##39s\n",
    "output_z, loss_mask, loss_mp, batchInd=fullBUTT_GPU(gen_obj, ref_map_base , target_midpoint, batch_size=100,cycles=200, input_z=None, \n",
    "                          rate=0.05, target_ep=[4,5,6,7], num_helices=4, oneRef=True,\n",
    "                          scale=100.0, z_size=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Size:  10000\n",
      "Passing Filters:  2128\n"
     ]
    }
   ],
   "source": [
    "# final_ep = buttress_ep_from_z(gen_obj, output_z[-1], current_quad, loss_mp[-1], loss_mask[-1], batchInd, \n",
    "#                               max_loss_mp=0.05, max_loss_mask=0.001)\n",
    "\n",
    "out_ep, uInd =buttress_ep_from_z_mask_only(gen_obj, output_z[-1], loss_mask[-1], batchInd,  max_out= 200,\n",
    "                                           max_loss_mask = 0.0005, print_stats= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fa, fa_reflect, ftm = align_generated_to_starting_ep(out_ep, current_quad[uInd], target_midpoint[uInd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ep =guess_reflection(fa, fa_reflect, ftm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_ep2 = np.concatenate((master_ep[uInd],final_ep[:,4:,:]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 8, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_ep2.shape \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = 1\n",
    "#starting concat special to orient points with original, helices to intialize directionality of addition (z refelect)\n",
    "#points unused except for this orientation step and maintaining distance maps indexing\n",
    "current_quad_prez = np.concatenate((master_ep2[:,mi*4:(mi+1)*4,:],master_ep2[:,mi*4:(mi+1)*4,:] ), axis=1)\n",
    "\n",
    "current_quad = rotate_base_tri_Zplane(current_quad_prez,  target_point=4, index_mobile=[1,2,3])\n",
    "\n",
    "#find reasonable midpoint target to backprop from\n",
    "cq_mp = get_midpoint(current_quad, helices_desired=[0,1],num_helices=4)\n",
    "target_midpoint = cq_mp + np.array([[0,0,9]])\n",
    "start_dist = np.expand_dims(current_quad,axis=1) - np.expand_dims(current_quad,axis=2)\n",
    "dist = np.sqrt(np.sum(start_dist**2, 3))\n",
    "dist = dist.reshape((dist.shape[0],-1))\n",
    "\n",
    "#will need to add method to convert helix 1,2,3,4 to just helix 1,2 (remove 1,2 convert 3,4 to )\n",
    "ref_map_base = ref_distmap_index(dist, num_helices=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_ep2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_ep2 = np.concatenate((master_ep[uInd],fa_reflect[:,4:,:]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(10):\n",
    "    hf.HelicalProtein.makePointPDB(master_ep2[x] ,f't{x}.pdb',outDirec='output/') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#method to view points in pymol  \n",
    "hf.HelicalProtein.makePointPDB(current_quad_prez[uInd][0],f't1.pdb',outDirec='output/')\n",
    "hf.HelicalProtein.makePointPDB(final_aligned[0] ,f't2.pdb',outDirec='output/') \n",
    "hf.HelicalProtein.makePointPDB(fa_reflect[0] ,f't3.pdb',outDirec='output/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate new ep onto quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need just 4 ep per layer, aka 2 helix unit additions.\n",
    "#master_ep = np.zeros((batch,4,3))\n",
    "#seed with base two units, need distance map\n",
    "\n",
    "mi = 0\n",
    "master_ep = zp_ep_mp[ref_ind ,:4,...]\n",
    "\n",
    "\n",
    "#distances indexed from generator are for helix quads\n",
    "#though the unit here is technically helix pairs\n",
    "#zeros are padded to maintain consistency for distance indices functions\n",
    "current_quad = np.concatenate((master_ep,np.zeros_like(master_ep)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_ep = np.concatenate((master_ep[uInd], final_ep[:,4:,...]), axis=1) #add endpoints to buttressed lest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi=1\n",
    "current_quad = np.concatenate((master_ep[:,mi*4:],np.zeros_like(master_ep[:,mi*4:])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.83,  4.  , -3.06],\n",
       "       [-7.85, -8.03, -8.82],\n",
       "       [-4.91, -8.82, -0.95],\n",
       "       [ 7.38, -5.19, 10.82],\n",
       "       [ 0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_quad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.87,   6.71,  -6.55],\n",
       "       [-11.21,  -3.73,   1.3 ],\n",
       "       [ -4.28,  -0.96,   9.06],\n",
       "       [ 10.9 ,  16.01,  -1.81],\n",
       "       [ 11.83,   4.  ,  -3.06],\n",
       "       [ -7.85,  -8.03,  -8.82],\n",
       "       [ -4.91,  -8.82,  -0.95],\n",
       "       [  7.38,  -5.19,  10.82]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ep[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_zp_ep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-711aa4c982ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m npose = np.concatenate((new_zp_ep, np.ones((new_zp_ep.shape[0],\n\u001b[0m\u001b[0;32m      2\u001b[0m                                             new_zp_ep.shape[1],1))),axis=2) # add rotation dimension\n\u001b[0;32m      3\u001b[0m \u001b[0minv_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxform_to_superimpose_nposes\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnew_zp_ep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaster_ep\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muInd\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_mobile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mref_resnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0morig_coord_new_ep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxform_npose_2batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minv_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnpose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# remove rotation dimension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_zp_ep' is not defined"
     ]
    }
   ],
   "source": [
    "npose = np.concatenate((new_zp_ep, np.ones((new_zp_ep.shape[0],\n",
    "                                            new_zp_ep.shape[1],1))),axis=2) # add rotation dimension\n",
    "inv_x = xform_to_superimpose_nposes( new_zp_ep, master_ep[uInd], index_mobile=[1,2,3],ref_resnum=[1,2,3] )\n",
    "\n",
    "orig_coord_new_ep = xform_npose_2batch(inv_x,npose)[...,:3] # remove rotation dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.12,   5.95,  -0.54],\n",
       "       [ -8.31,   7.91,   6.58],\n",
       "       [ -8.97,   3.65,  -2.58],\n",
       "       [ 11.79,   0.34, -16.05],\n",
       "       [ 10.87,  -4.44,  -6.8 ],\n",
       "       [ -1.04,   0.51,  13.15],\n",
       "       [ -1.27,  -9.1 ,  10.86],\n",
       "       [-12.19,  -4.83,  -4.63]])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_coord_new_ep[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#method to view points in pymol  \n",
    "hf.HelicalProtein.makePointPDB(orig_coord_new_ep[0][:4],f't1.pdb',outDirec='output/')\n",
    "hf.HelicalProtein.makePointPDB(master_ep[uInd][0] ,f't2.pdb',outDirec='output/')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.83,  2.98,  0.86],\n",
       "       [10.43, 13.66, 15.2 ],\n",
       "       [15.56, 13.53, 13.64],\n",
       "       [14.86,  7.09, -9.64]])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_ep[uInd][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 36, 47, 47, 36,  9, 24, 97, 36,  7, 44, 17,  7, 47, 57, 26, 36,\n",
       "       17,  9, 94, 97, 97, 36, 79, 63, 24, 57, 20, 17, 57, 52, 73, 58, 10,\n",
       "       43, 57, 29, 19])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uInd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def xform_to_z_plane(mobile, index_mobile=[0,1,2]):\n",
    "    \"\"\"rotate points into the z-plane for trilaterization. needs additional translation/reflection\"\"\"\n",
    "\n",
    "    mobile_stub = get_stubs_from_points(mobile, index=index_mobile)\n",
    "    mobile_stub_inv = np.linalg.inv(mobile_stub)\n",
    "    \n",
    "    z_plane_ref = np.repeat(np.array([[[0,0,0],[1,0,0],[1,1,0]]]), mobile.shape[0],axis=0)\n",
    "\n",
    "    ref_stub = get_stubs_from_points(z_plane_ref, index=[0,1,2])\n",
    "\n",
    "    xform = ref_stub @ mobile_stub_inv\n",
    "\n",
    "    return xform\n",
    "\n",
    "\n",
    "def rotate_base_tri_Zplane(endpoint_midpoints, target_point=4, index_mobile=[1,2,3], returnRotMat=False):\n",
    "    \"\"\"rotate points into the z-plane for trilaterization. Target point ensures that point is positive in Z\"\"\"\n",
    "    tp = target_point #target point\n",
    "    zplanexform = xform_to_z_plane(endpoint_midpoints,index_mobile=index_mobile) #one index start base triangle, default\n",
    "    #add one for npose rot calc\n",
    "    npose = np.concatenate((endpoint_midpoints, np.ones((endpoint_midpoints.shape[0],\n",
    "                                                         endpoint_midpoints.shape[1],1))),axis=2) \n",
    "    rot = xform_npose_2batch(zplanexform,npose) # double batch matrix multiplication, see npose, for one batch\n",
    "\n",
    "    #translate X domain to place first index of \"index_mobile\" to 0,0,0\n",
    "    rot[:,:,0] = rot[:,:,0]-np.expand_dims(rot[:,index_mobile[0],0],axis=1)\n",
    "    #based on target point guaranteed to be positive\n",
    "    #reflect new points across the z axis to positive if negative to match just choosing positive solutions\n",
    "    rot[...,2][rot[:,tp,2]<0] = -rot[...,2][rot[:,tp,2]<0]\n",
    "    \n",
    "    if not returnRotMat:\n",
    "        return rot[...,:3] #remove npose rotate dimension\n",
    "    else:\n",
    "        return rot[...,:3], zplanexform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to view points in pymol  \n",
    "hf.HelicalProtein.makePointPDB(current_quad[uInd][0],f't1.pdb',outDirec='output/')\n",
    "hf.HelicalProtein.makePointPDB(new_zp_ep[0] ,f't2.pdb',outDirec='output/')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fa_tfpy",
   "language": "python",
   "name": "fa_tfpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
