{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d3bd880d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device name /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "import argparse\n",
    "import textwrap\n",
    "\n",
    "import util.plot as pt\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    device_name = tf.test.gpu_device_name()\n",
    "else:\n",
    "    device_name = '\\CPU:0'\n",
    "    \n",
    "print(f'device name {device_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dd6e5cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'data/Fits_4H_dm_phi.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c1e39c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare transformed Helix Fit Parameters for GAN from FitTransform\n",
    "\n",
    "rr = np.load(f'{name}', allow_pickle=True)\n",
    "X_train_hfp, y_train_hfp, featnames_hfp = [rr[f] for f in rr.files]\n",
    "\n",
    "#remove phi1\n",
    "X_train_hfp = X_train_hfp[:,:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff5506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8f50bf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just confirming that the y_trains indices are still equal\n",
    "# for i,c in enumerate(y_train_hfp):\n",
    "#     if c != y_train[i]:\n",
    "#         print(c)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "971bc301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2345\n",
      "1 472\n",
      "2 536\n",
      "3 2105\n",
      "4 955\n",
      "5 1625\n",
      "6 1454\n",
      "7 1190\n",
      "8 4160\n",
      "9 321\n",
      "10 1495\n",
      "11 700\n",
      "12 708\n",
      "13 187\n",
      "14 1024\n",
      "15 531\n",
      "16 373\n",
      "17 1162\n",
      "18 761\n",
      "19 2155\n",
      "20 992\n",
      "21 503\n",
      "22 696\n",
      "23 663\n",
      "24 289\n",
      "25 475\n"
     ]
    }
   ],
   "source": [
    "clusterLoad = \"Clustering/data/refData.npz\"\n",
    "with np.load(f'{clusterLoad}', allow_pickle=True) as rr:\n",
    "    y_, y_train, X_train, featNames = [rr[f] for f in rr.files]\n",
    "    \n",
    "cluster_labels = np.unique(y_)\n",
    "n_clusters = cluster_labels.shape[0]\n",
    "\n",
    "# nameList = []\n",
    "\n",
    "# for x in clusNums:\n",
    "#     self.nameList.extend(self.y_train[np.where(self.y_==x)])\n",
    "for x in cluster_labels:\n",
    "    print(x, y_[y_==x].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aff668c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_hfp[y_!=7]\n",
    "y_train = y_train_hfp[y_!=7]\n",
    "\n",
    "mm = MinMaxScaler(feature_range=(-1,1))\n",
    "X_train = mm.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "62d008cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_network(num_hidden_layers = 3,num_hidden_units = 64,num_output_units =28):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add(tf.keras.layers.Dense(units=num_hidden_units, use_bias=False))\n",
    "        model.add(tf.keras.layers.LeakyReLU())\n",
    "        \n",
    "    model.add(tf.keras.layers.Dense(units=num_output_units,activation='tanh'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def make_discriminator_network(num_hidden_layers=3, num_hidden_units=64, num_output_units =1,drop=0.1):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add(tf.keras.layers.Dense(units=num_hidden_units))\n",
    "        model.add(tf.keras.layers.LeakyReLU())\n",
    "        model.add(tf.keras.layers.Dropout(rate=drop))\n",
    "        \n",
    "    model.add(tf.keras.layers.Dense(units=num_output_units,activation=None))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def saveNetwork_Scaler(genMod,disMod,scaler,name,direc='data/'):\n",
    "    \n",
    "    joblib.dump(scaler, f'{direc}{name}_mm.gz')\n",
    "    genMod.save(f'{direc}{name}.h5',overwrite=True,include_optimizer=True, save_format='h5')\n",
    "    disMod.save(f'{direc}{name}disc.h5',overwrite=True,include_optimizer=True, save_format='h5')\n",
    "    \n",
    "def saveTrainLoss(loss_in,dvals_in,name,direc='data/'):\n",
    "    \n",
    "    data = [loss_in,dvals_in]\n",
    "\n",
    "    with open(f'{direc}{name}.pkl','wb') as f:\n",
    "        pickle.dump(data, f)   \n",
    "        \n",
    "def loadTrainLoss(name,direc='data/'):\n",
    " \n",
    "    with open(f'{direc}{name}.pkl','rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    all_losses = data[0]\n",
    "    dval_losses = data[1]\n",
    "    \n",
    "    return all_losses, dval_losses\n",
    "\n",
    "def init_model(X_train, y_train, batch=64 ,zIn=12, g_layers=3, g_size=64, d_layers =3, d_size=64,\n",
    "               zmode='uniform',discDrop=0.1, normalization=None):\n",
    "\n",
    "    z_size = zIn\n",
    "    mode_z = zmode\n",
    "    gen_hidden_layers= g_layers\n",
    "    gen_hidden_size = g_size\n",
    "    disc_hidden_layers = d_layers\n",
    "    disc_hidden_size = d_size\n",
    "    batch_size = batch\n",
    "\n",
    "    h4_feat =X_train.shape[1]\n",
    "\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices((tf.cast(X_train, tf.float32), y_train))\n",
    "    ds_train = ds_train.shuffle(X_train.shape[0]) \n",
    "    ds_train = ds_train.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    with tf.device(device_name):\n",
    "        gen_model = make_generator_network(num_hidden_layers=gen_hidden_layers,\n",
    "                                   num_hidden_units = gen_hidden_size,\n",
    "                                   num_output_units = h4_feat)\n",
    "        gen_model.build(input_shape=(None,z_size))\n",
    "        disc_model = make_discriminator_network(num_hidden_layers=disc_hidden_layers,\n",
    "                                       num_hidden_units =disc_hidden_size,drop=discDrop)\n",
    "        disc_model.build(input_shape=(None, h4_feat))\n",
    "\n",
    "    return  gen_model, disc_model, ds_train\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9afc4039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (26687, 28)\n"
     ]
    }
   ],
   "source": [
    "trainSettings = {'batch':4,\n",
    "            'input_size':12,\n",
    "            'input_dist':'uniform',\n",
    "            'gen_layers':3,\n",
    "            'gen_size':64,\n",
    "            'disc_layers':3,\n",
    "            'disc_size':64,\n",
    "            'disc_dropOut':0.1,\n",
    "            'Adam_gen_rate':.0001,\n",
    "            'Adam_disc_rate':.0001,\n",
    "            'CheckPointDirec':'checkpoints',\n",
    "            'CheckPointsKeep':10,\n",
    "            'epochs':300}\n",
    "\n",
    "saveLoss=True\n",
    "nameOut= 'ClusterRemoval_Test'\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "    \n",
    "nameRun = nameOut\n",
    "#base_folder = time.strftime('log/%y%b%d_%I%M%p', time.localtime())\n",
    "base_folder = 'log/GAN'\n",
    "base_folder = f'{base_folder}{nameRun}/'\n",
    "if not os.path.exists(base_folder):\n",
    "    os.makedirs(base_folder)\n",
    "subfolders = ['checkpoints','loss']\n",
    "for subfolder in subfolders:\n",
    "    if not os.path.exists(base_folder + subfolder):\n",
    "        os.makedirs(base_folder + subfolder)\n",
    "\n",
    "settings = trainSettings\n",
    "    \n",
    "@tf.function   \n",
    "def train_step(input_z,input_real):\n",
    "    ##Compute generator's loss\n",
    "    with tf.GradientTape() as g_tape:\n",
    "        g_output = gen_model(input_z)\n",
    "        d_logits_fake = disc_model(g_output, training=True)\n",
    "        labels_real = tf.ones_like(d_logits_fake)\n",
    "        g_loss = loss_fn(y_true=labels_real, y_pred = d_logits_fake)\n",
    "\n",
    "    g_grads = g_tape.gradient(g_loss, gen_model.trainable_variables)\n",
    "\n",
    "    ##Optimization: Apply the gradients    \n",
    "    g_optimizer.apply_gradients(grads_and_vars=zip(g_grads,gen_model.trainable_variables))\n",
    "\n",
    "    ##Compute the discriminators loss\n",
    "    with tf.GradientTape() as d_tape:\n",
    "        d_logits_real = disc_model(input_real, training=True)\n",
    "        d_labels_real = tf.ones_like(d_logits_real)\n",
    "\n",
    "        d_loss_real = loss_fn(y_true=d_labels_real, y_pred = d_logits_real)\n",
    "\n",
    "        d_logits_fake = disc_model(g_output, training=True)\n",
    "        d_labels_fake = tf.zeros_like(d_logits_fake)\n",
    "\n",
    "        d_loss_fake = loss_fn(y_true=d_labels_fake, y_pred=d_logits_fake)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "    ##compute the gradients of d_loss\n",
    "    d_grads = d_tape.gradient(d_loss, disc_model.trainable_variables)\n",
    "\n",
    "    ## Optimization : Apply the gradients\n",
    "    d_optimizer.apply_gradients(grads_and_vars=zip(d_grads,disc_model.trainable_variables))\n",
    "    d_probs_real = tf.reduce_mean(tf.sigmoid(d_logits_real))\n",
    "    d_probs_fake = tf.reduce_mean(tf.sigmoid(d_logits_fake))\n",
    "\n",
    "    return g_loss, d_loss, d_loss_real, d_loss_fake, d_probs_real, d_probs_fake\n",
    "\n",
    "\n",
    "\n",
    "def train(ds_train, epochs, manager, batch_size, z_size):\n",
    "\n",
    "    checkpoint.restore(manager.latest_checkpoint)\n",
    "    if manager.latest_checkpoint:\n",
    "        print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "    else:\n",
    "        print(\"Initializing from scratch.\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        epoch_losses, epoch_d_vals = [],[]\n",
    "\n",
    "        for i, (input_real,name) in enumerate(ds_train):\n",
    "            input_z = tf.random.uniform(shape=(batch_size, z_size), minval=-1, maxval=1)\n",
    "            g_loss, d_loss, d_loss_real, d_loss_fake, d_probs_real, d_probs_fake = train_step(input_z,input_real)\n",
    "\n",
    "            epoch_losses.append(( g_loss.numpy(), d_loss.numpy(), d_loss_real.numpy(), d_loss_fake.numpy()))\n",
    "            epoch_d_vals.append((d_probs_real.numpy(), d_probs_fake.numpy()))\n",
    "\n",
    "\n",
    "        checkpoint.step.assign_add(1)\n",
    "        if (epoch + 1) % 25 == 0:\n",
    "            save_path = manager.save()\n",
    "            print(\"Saved checkpoint for step {}: {}\".format(int(checkpoint.step), save_path))\n",
    "\n",
    "\n",
    "        all_losses.append(epoch_losses)\n",
    "        all_d_vals.append(epoch_d_vals)\n",
    "\n",
    "        track = f'Epoch {epoch:03d} |  ET {(time.time()-start_time)/60:.2f} min AvgLosses >> G/D '\n",
    "        track = f'{track}{(np.mean(all_losses[-1][0],axis=0)):.3f}/{(np.mean(all_losses[-1][1],axis=0)):.3f}'\n",
    "        track = f'{track} D Real :{(np.mean(all_losses[-1][2],axis=0)):.3f}'\n",
    "        track = f'{track} D Fake :{(np.mean(all_losses[-1][3],axis=0)):.3f}'\n",
    "\n",
    "        print(track)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bf3c984c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing from scratch.\n",
      "Epoch 000 |  ET 0.23 min AvgLosses >> G/D 0.815/0.831 D Real :0.808 D Fake :0.813\n",
      "Epoch 001 |  ET 0.44 min AvgLosses >> G/D 0.850/0.854 D Real :0.818 D Fake :0.816\n",
      "Epoch 002 |  ET 0.66 min AvgLosses >> G/D 0.929/0.907 D Real :0.867 D Fake :0.901\n",
      "Epoch 003 |  ET 0.88 min AvgLosses >> G/D 0.919/0.945 D Real :0.869 D Fake :0.831\n",
      "Epoch 004 |  ET 1.10 min AvgLosses >> G/D 0.888/0.898 D Real :0.798 D Fake :0.867\n",
      "Epoch 005 |  ET 1.32 min AvgLosses >> G/D 0.833/0.859 D Real :0.883 D Fake :0.761\n",
      "Epoch 006 |  ET 1.54 min AvgLosses >> G/D 0.897/0.810 D Real :0.933 D Fake :0.882\n",
      "Epoch 007 |  ET 1.75 min AvgLosses >> G/D 0.802/0.870 D Real :0.937 D Fake :0.899\n",
      "Epoch 008 |  ET 1.97 min AvgLosses >> G/D 0.808/0.763 D Real :0.714 D Fake :0.890\n",
      "Epoch 009 |  ET 2.18 min AvgLosses >> G/D 0.960/0.849 D Real :1.032 D Fake :0.798\n",
      "Epoch 010 |  ET 2.40 min AvgLosses >> G/D 0.889/0.800 D Real :0.796 D Fake :0.885\n",
      "Epoch 011 |  ET 2.61 min AvgLosses >> G/D 0.810/0.866 D Real :0.794 D Fake :0.757\n",
      "Epoch 012 |  ET 2.82 min AvgLosses >> G/D 0.851/0.904 D Real :0.799 D Fake :0.894\n",
      "Epoch 013 |  ET 3.04 min AvgLosses >> G/D 0.924/0.858 D Real :0.888 D Fake :0.847\n",
      "Epoch 014 |  ET 3.26 min AvgLosses >> G/D 0.810/0.886 D Real :0.877 D Fake :0.829\n",
      "Epoch 015 |  ET 3.47 min AvgLosses >> G/D 0.697/0.895 D Real :0.878 D Fake :0.759\n",
      "Epoch 016 |  ET 3.69 min AvgLosses >> G/D 0.849/0.851 D Real :0.901 D Fake :0.722\n",
      "Epoch 017 |  ET 3.91 min AvgLosses >> G/D 0.778/0.871 D Real :0.766 D Fake :0.922\n",
      "Epoch 018 |  ET 4.13 min AvgLosses >> G/D 0.938/0.816 D Real :0.822 D Fake :0.771\n",
      "Epoch 019 |  ET 4.35 min AvgLosses >> G/D 0.913/0.866 D Real :0.808 D Fake :0.805\n",
      "Epoch 020 |  ET 4.56 min AvgLosses >> G/D 0.898/0.786 D Real :0.795 D Fake :0.834\n",
      "Epoch 021 |  ET 4.78 min AvgLosses >> G/D 0.800/0.855 D Real :0.863 D Fake :0.817\n",
      "Epoch 022 |  ET 4.99 min AvgLosses >> G/D 0.963/0.904 D Real :0.882 D Fake :0.853\n",
      "Epoch 023 |  ET 5.21 min AvgLosses >> G/D 0.676/0.903 D Real :0.924 D Fake :0.887\n",
      "Saved checkpoint for step 26: log/GANClusterRemoval_Test/checkpoints\\ckpt-1\n",
      "Epoch 024 |  ET 5.43 min AvgLosses >> G/D 0.820/0.958 D Real :1.116 D Fake :0.898\n",
      "Epoch 025 |  ET 5.65 min AvgLosses >> G/D 0.935/0.935 D Real :1.052 D Fake :0.965\n",
      "Epoch 026 |  ET 5.87 min AvgLosses >> G/D 1.011/0.862 D Real :0.807 D Fake :0.772\n",
      "Epoch 027 |  ET 6.09 min AvgLosses >> G/D 0.929/0.868 D Real :0.971 D Fake :0.726\n",
      "Epoch 028 |  ET 6.31 min AvgLosses >> G/D 0.912/0.935 D Real :0.988 D Fake :0.986\n",
      "Epoch 029 |  ET 6.53 min AvgLosses >> G/D 0.832/0.908 D Real :0.812 D Fake :0.871\n",
      "Epoch 030 |  ET 6.75 min AvgLosses >> G/D 0.925/0.881 D Real :1.125 D Fake :0.839\n",
      "Epoch 031 |  ET 6.97 min AvgLosses >> G/D 0.923/1.071 D Real :0.988 D Fake :0.927\n",
      "Epoch 032 |  ET 7.18 min AvgLosses >> G/D 0.896/1.059 D Real :0.783 D Fake :0.716\n",
      "Epoch 033 |  ET 7.41 min AvgLosses >> G/D 0.568/0.698 D Real :0.823 D Fake :0.945\n",
      "Epoch 034 |  ET 7.62 min AvgLosses >> G/D 1.002/0.807 D Real :0.844 D Fake :0.857\n",
      "Epoch 035 |  ET 7.85 min AvgLosses >> G/D 1.128/0.677 D Real :0.810 D Fake :0.882\n",
      "Epoch 036 |  ET 8.07 min AvgLosses >> G/D 0.927/0.840 D Real :0.746 D Fake :0.802\n",
      "Epoch 037 |  ET 8.30 min AvgLosses >> G/D 0.829/0.867 D Real :0.754 D Fake :0.729\n",
      "Epoch 038 |  ET 8.52 min AvgLosses >> G/D 0.936/0.742 D Real :0.909 D Fake :0.815\n",
      "Epoch 039 |  ET 8.80 min AvgLosses >> G/D 1.138/0.852 D Real :0.867 D Fake :0.923\n",
      "Epoch 040 |  ET 9.07 min AvgLosses >> G/D 0.747/0.833 D Real :1.095 D Fake :0.857\n",
      "Epoch 041 |  ET 9.30 min AvgLosses >> G/D 0.811/1.091 D Real :0.845 D Fake :0.949\n",
      "Epoch 042 |  ET 9.53 min AvgLosses >> G/D 0.795/0.715 D Real :0.805 D Fake :0.754\n",
      "Epoch 043 |  ET 9.78 min AvgLosses >> G/D 0.720/0.853 D Real :0.734 D Fake :0.822\n",
      "Epoch 044 |  ET 10.03 min AvgLosses >> G/D 0.846/0.849 D Real :1.005 D Fake :0.994\n",
      "Epoch 045 |  ET 10.28 min AvgLosses >> G/D 0.706/0.736 D Real :0.844 D Fake :0.871\n",
      "Epoch 046 |  ET 10.53 min AvgLosses >> G/D 0.825/0.850 D Real :0.927 D Fake :0.744\n",
      "Epoch 047 |  ET 10.78 min AvgLosses >> G/D 0.906/1.077 D Real :0.719 D Fake :0.742\n",
      "Epoch 048 |  ET 11.03 min AvgLosses >> G/D 0.853/0.881 D Real :0.774 D Fake :0.916\n",
      "Saved checkpoint for step 51: log/GANClusterRemoval_Test/checkpoints\\ckpt-2\n",
      "Epoch 049 |  ET 11.26 min AvgLosses >> G/D 0.909/1.020 D Real :0.744 D Fake :1.114\n",
      "Epoch 050 |  ET 11.50 min AvgLosses >> G/D 0.776/0.962 D Real :0.734 D Fake :0.955\n",
      "Epoch 051 |  ET 11.74 min AvgLosses >> G/D 0.921/0.741 D Real :0.881 D Fake :0.863\n",
      "Epoch 052 |  ET 12.00 min AvgLosses >> G/D 0.891/0.943 D Real :0.743 D Fake :0.778\n",
      "Epoch 053 |  ET 12.27 min AvgLosses >> G/D 0.923/0.703 D Real :0.785 D Fake :0.846\n",
      "Epoch 054 |  ET 12.50 min AvgLosses >> G/D 0.788/0.826 D Real :0.817 D Fake :0.826\n",
      "Epoch 055 |  ET 12.75 min AvgLosses >> G/D 1.119/0.910 D Real :0.947 D Fake :0.890\n",
      "Epoch 056 |  ET 13.00 min AvgLosses >> G/D 0.830/0.824 D Real :0.816 D Fake :1.071\n",
      "Epoch 057 |  ET 13.24 min AvgLosses >> G/D 1.174/0.843 D Real :0.982 D Fake :0.971\n",
      "Epoch 058 |  ET 13.48 min AvgLosses >> G/D 0.968/0.746 D Real :1.042 D Fake :0.874\n",
      "Epoch 059 |  ET 13.73 min AvgLosses >> G/D 0.759/0.570 D Real :0.757 D Fake :0.996\n",
      "Epoch 060 |  ET 13.97 min AvgLosses >> G/D 0.778/0.806 D Real :1.191 D Fake :0.853\n",
      "Epoch 061 |  ET 14.21 min AvgLosses >> G/D 1.076/0.948 D Real :0.955 D Fake :1.067\n",
      "Epoch 062 |  ET 14.47 min AvgLosses >> G/D 0.749/0.866 D Real :0.769 D Fake :0.758\n",
      "Epoch 063 |  ET 14.71 min AvgLosses >> G/D 0.860/0.800 D Real :0.887 D Fake :0.591\n",
      "Epoch 064 |  ET 14.96 min AvgLosses >> G/D 0.806/0.956 D Real :0.947 D Fake :0.789\n",
      "Epoch 065 |  ET 15.22 min AvgLosses >> G/D 0.665/0.778 D Real :0.804 D Fake :0.835\n",
      "Epoch 066 |  ET 15.46 min AvgLosses >> G/D 0.900/0.946 D Real :0.700 D Fake :0.711\n",
      "Epoch 067 |  ET 15.68 min AvgLosses >> G/D 0.784/0.743 D Real :0.854 D Fake :0.722\n",
      "Epoch 068 |  ET 15.93 min AvgLosses >> G/D 0.743/0.884 D Real :0.825 D Fake :0.622\n",
      "Epoch 069 |  ET 16.16 min AvgLosses >> G/D 0.668/0.869 D Real :0.879 D Fake :0.996\n",
      "Epoch 070 |  ET 16.39 min AvgLosses >> G/D 0.998/0.773 D Real :0.825 D Fake :0.728\n",
      "Epoch 071 |  ET 16.63 min AvgLosses >> G/D 0.589/0.660 D Real :0.729 D Fake :0.822\n",
      "Epoch 072 |  ET 16.86 min AvgLosses >> G/D 0.829/0.889 D Real :0.723 D Fake :1.118\n",
      "Epoch 073 |  ET 17.08 min AvgLosses >> G/D 0.950/0.890 D Real :0.657 D Fake :0.932\n",
      "Saved checkpoint for step 76: log/GANClusterRemoval_Test/checkpoints\\ckpt-3\n",
      "Epoch 074 |  ET 17.30 min AvgLosses >> G/D 0.923/0.983 D Real :0.740 D Fake :0.744\n",
      "Epoch 075 |  ET 17.52 min AvgLosses >> G/D 1.049/0.657 D Real :0.757 D Fake :0.853\n",
      "Epoch 076 |  ET 17.74 min AvgLosses >> G/D 0.808/0.929 D Real :0.803 D Fake :0.765\n",
      "Epoch 077 |  ET 17.96 min AvgLosses >> G/D 0.851/0.875 D Real :0.700 D Fake :1.001\n",
      "Epoch 078 |  ET 18.17 min AvgLosses >> G/D 0.832/1.135 D Real :1.002 D Fake :0.824\n",
      "Epoch 079 |  ET 18.39 min AvgLosses >> G/D 0.935/0.914 D Real :0.901 D Fake :0.599\n",
      "Epoch 080 |  ET 18.61 min AvgLosses >> G/D 0.679/0.802 D Real :0.802 D Fake :0.761\n",
      "Epoch 081 |  ET 18.83 min AvgLosses >> G/D 0.924/0.892 D Real :0.888 D Fake :1.096\n",
      "Epoch 082 |  ET 19.04 min AvgLosses >> G/D 0.732/0.925 D Real :0.824 D Fake :0.714\n",
      "Epoch 083 |  ET 19.25 min AvgLosses >> G/D 0.916/0.755 D Real :0.709 D Fake :0.963\n",
      "Epoch 084 |  ET 19.47 min AvgLosses >> G/D 0.728/0.918 D Real :1.076 D Fake :1.119\n",
      "Epoch 085 |  ET 19.69 min AvgLosses >> G/D 0.808/0.839 D Real :0.734 D Fake :0.575\n",
      "Epoch 086 |  ET 19.90 min AvgLosses >> G/D 0.812/0.834 D Real :0.842 D Fake :0.684\n",
      "Epoch 087 |  ET 20.12 min AvgLosses >> G/D 0.739/0.797 D Real :0.827 D Fake :0.780\n",
      "Epoch 088 |  ET 20.33 min AvgLosses >> G/D 0.716/0.777 D Real :0.954 D Fake :0.958\n",
      "Epoch 089 |  ET 20.55 min AvgLosses >> G/D 0.712/0.704 D Real :0.762 D Fake :0.970\n",
      "Epoch 090 |  ET 20.77 min AvgLosses >> G/D 0.940/0.855 D Real :0.839 D Fake :0.842\n",
      "Epoch 091 |  ET 20.98 min AvgLosses >> G/D 0.642/0.745 D Real :0.892 D Fake :0.602\n",
      "Epoch 092 |  ET 21.20 min AvgLosses >> G/D 0.731/1.080 D Real :0.757 D Fake :0.826\n",
      "Epoch 093 |  ET 21.42 min AvgLosses >> G/D 0.831/0.524 D Real :0.848 D Fake :0.859\n",
      "Epoch 094 |  ET 21.64 min AvgLosses >> G/D 0.635/0.993 D Real :0.697 D Fake :0.771\n",
      "Epoch 095 |  ET 21.87 min AvgLosses >> G/D 1.009/0.759 D Real :0.904 D Fake :0.889\n",
      "Epoch 096 |  ET 22.09 min AvgLosses >> G/D 1.018/0.873 D Real :1.095 D Fake :0.933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 097 |  ET 22.31 min AvgLosses >> G/D 0.747/0.911 D Real :0.822 D Fake :0.753\n",
      "Epoch 098 |  ET 22.53 min AvgLosses >> G/D 0.856/0.638 D Real :1.013 D Fake :0.951\n",
      "Saved checkpoint for step 101: log/GANClusterRemoval_Test/checkpoints\\ckpt-4\n",
      "Epoch 099 |  ET 22.75 min AvgLosses >> G/D 0.801/0.830 D Real :0.718 D Fake :0.904\n",
      "Epoch 100 |  ET 22.97 min AvgLosses >> G/D 0.718/0.821 D Real :0.722 D Fake :0.839\n",
      "Epoch 101 |  ET 23.19 min AvgLosses >> G/D 0.866/0.978 D Real :0.782 D Fake :1.306\n",
      "Epoch 102 |  ET 23.41 min AvgLosses >> G/D 0.830/0.821 D Real :0.917 D Fake :0.799\n",
      "Epoch 103 |  ET 23.63 min AvgLosses >> G/D 0.907/0.980 D Real :1.062 D Fake :0.904\n",
      "Epoch 104 |  ET 23.85 min AvgLosses >> G/D 0.628/0.748 D Real :0.916 D Fake :0.890\n",
      "Epoch 105 |  ET 24.07 min AvgLosses >> G/D 0.731/0.729 D Real :1.003 D Fake :0.828\n",
      "Epoch 106 |  ET 24.30 min AvgLosses >> G/D 0.900/1.252 D Real :0.825 D Fake :0.680\n",
      "Epoch 107 |  ET 24.51 min AvgLosses >> G/D 1.072/0.726 D Real :0.690 D Fake :1.004\n",
      "Epoch 108 |  ET 24.73 min AvgLosses >> G/D 0.884/0.837 D Real :0.981 D Fake :0.735\n",
      "Epoch 109 |  ET 24.95 min AvgLosses >> G/D 0.780/0.942 D Real :0.931 D Fake :0.624\n",
      "Epoch 110 |  ET 25.17 min AvgLosses >> G/D 1.111/0.706 D Real :0.914 D Fake :0.781\n",
      "Epoch 111 |  ET 25.39 min AvgLosses >> G/D 0.767/1.133 D Real :1.075 D Fake :0.738\n",
      "Epoch 112 |  ET 25.61 min AvgLosses >> G/D 0.825/0.904 D Real :1.038 D Fake :0.758\n",
      "Epoch 113 |  ET 25.83 min AvgLosses >> G/D 0.660/0.876 D Real :1.035 D Fake :1.082\n",
      "Epoch 114 |  ET 26.06 min AvgLosses >> G/D 0.654/1.016 D Real :0.805 D Fake :0.726\n",
      "Epoch 115 |  ET 26.28 min AvgLosses >> G/D 0.675/0.982 D Real :0.812 D Fake :0.714\n",
      "Epoch 116 |  ET 26.50 min AvgLosses >> G/D 0.844/0.816 D Real :0.897 D Fake :0.699\n",
      "Epoch 117 |  ET 26.72 min AvgLosses >> G/D 0.681/0.886 D Real :0.860 D Fake :0.923\n",
      "Epoch 118 |  ET 26.95 min AvgLosses >> G/D 0.876/0.769 D Real :0.844 D Fake :0.681\n",
      "Epoch 119 |  ET 27.17 min AvgLosses >> G/D 0.949/0.669 D Real :0.924 D Fake :0.786\n",
      "Epoch 120 |  ET 27.39 min AvgLosses >> G/D 1.014/0.963 D Real :0.776 D Fake :0.949\n",
      "Epoch 121 |  ET 27.61 min AvgLosses >> G/D 0.714/0.866 D Real :0.822 D Fake :0.879\n",
      "Epoch 122 |  ET 27.83 min AvgLosses >> G/D 0.792/0.793 D Real :0.912 D Fake :1.040\n",
      "Epoch 123 |  ET 28.05 min AvgLosses >> G/D 0.799/0.771 D Real :0.872 D Fake :0.500\n",
      "Saved checkpoint for step 126: log/GANClusterRemoval_Test/checkpoints\\ckpt-5\n",
      "Epoch 124 |  ET 28.26 min AvgLosses >> G/D 0.916/0.824 D Real :0.732 D Fake :0.939\n",
      "Epoch 125 |  ET 28.49 min AvgLosses >> G/D 0.514/0.809 D Real :0.946 D Fake :0.924\n",
      "Epoch 126 |  ET 28.70 min AvgLosses >> G/D 0.803/0.830 D Real :0.883 D Fake :0.801\n",
      "Epoch 127 |  ET 28.93 min AvgLosses >> G/D 0.823/0.772 D Real :0.793 D Fake :0.720\n",
      "Epoch 128 |  ET 29.15 min AvgLosses >> G/D 0.841/1.199 D Real :0.849 D Fake :1.019\n",
      "Epoch 129 |  ET 29.38 min AvgLosses >> G/D 1.119/1.006 D Real :0.622 D Fake :0.730\n",
      "Epoch 130 |  ET 29.61 min AvgLosses >> G/D 0.761/0.718 D Real :0.782 D Fake :0.826\n",
      "Epoch 131 |  ET 29.84 min AvgLosses >> G/D 0.881/0.815 D Real :0.640 D Fake :1.118\n",
      "Epoch 132 |  ET 30.07 min AvgLosses >> G/D 1.091/0.749 D Real :1.080 D Fake :0.881\n",
      "Epoch 133 |  ET 30.29 min AvgLosses >> G/D 0.829/0.943 D Real :0.915 D Fake :0.853\n",
      "Epoch 134 |  ET 30.52 min AvgLosses >> G/D 0.973/0.725 D Real :0.758 D Fake :1.011\n",
      "Epoch 135 |  ET 30.75 min AvgLosses >> G/D 1.216/0.860 D Real :0.881 D Fake :1.061\n",
      "Epoch 136 |  ET 30.98 min AvgLosses >> G/D 0.853/0.690 D Real :1.096 D Fake :0.761\n",
      "Epoch 137 |  ET 31.21 min AvgLosses >> G/D 0.873/0.812 D Real :0.749 D Fake :0.853\n",
      "Epoch 138 |  ET 31.44 min AvgLosses >> G/D 1.354/0.892 D Real :0.844 D Fake :1.218\n",
      "Epoch 139 |  ET 31.67 min AvgLosses >> G/D 0.564/0.742 D Real :0.967 D Fake :0.936\n",
      "Epoch 140 |  ET 31.89 min AvgLosses >> G/D 1.043/0.913 D Real :0.942 D Fake :0.758\n",
      "Epoch 141 |  ET 32.12 min AvgLosses >> G/D 1.000/0.876 D Real :1.034 D Fake :0.828\n",
      "Epoch 142 |  ET 32.35 min AvgLosses >> G/D 0.782/0.755 D Real :0.713 D Fake :0.768\n",
      "Epoch 143 |  ET 32.58 min AvgLosses >> G/D 1.168/1.243 D Real :0.964 D Fake :1.023\n",
      "Epoch 144 |  ET 32.81 min AvgLosses >> G/D 0.839/0.837 D Real :0.804 D Fake :0.836\n",
      "Epoch 145 |  ET 33.04 min AvgLosses >> G/D 0.818/0.734 D Real :0.794 D Fake :0.896\n",
      "Epoch 146 |  ET 33.27 min AvgLosses >> G/D 0.648/0.983 D Real :0.858 D Fake :0.999\n",
      "Epoch 147 |  ET 33.49 min AvgLosses >> G/D 0.808/0.619 D Real :0.724 D Fake :1.055\n",
      "Epoch 148 |  ET 33.72 min AvgLosses >> G/D 0.903/0.901 D Real :0.603 D Fake :0.843\n",
      "Saved checkpoint for step 151: log/GANClusterRemoval_Test/checkpoints\\ckpt-6\n",
      "Epoch 149 |  ET 33.96 min AvgLosses >> G/D 0.740/0.951 D Real :0.960 D Fake :0.814\n",
      "Epoch 150 |  ET 34.19 min AvgLosses >> G/D 1.028/0.849 D Real :1.055 D Fake :0.839\n",
      "Epoch 151 |  ET 34.42 min AvgLosses >> G/D 0.694/0.816 D Real :1.384 D Fake :0.871\n",
      "Epoch 152 |  ET 34.65 min AvgLosses >> G/D 0.905/0.816 D Real :0.678 D Fake :0.788\n",
      "Epoch 153 |  ET 34.88 min AvgLosses >> G/D 0.812/1.055 D Real :1.198 D Fake :0.940\n",
      "Epoch 154 |  ET 35.11 min AvgLosses >> G/D 0.817/0.756 D Real :0.890 D Fake :0.797\n",
      "Epoch 155 |  ET 35.35 min AvgLosses >> G/D 0.738/0.995 D Real :0.837 D Fake :0.814\n",
      "Epoch 156 |  ET 35.58 min AvgLosses >> G/D 0.790/1.096 D Real :0.748 D Fake :0.959\n",
      "Epoch 157 |  ET 35.81 min AvgLosses >> G/D 0.690/0.919 D Real :0.703 D Fake :0.713\n",
      "Epoch 158 |  ET 36.03 min AvgLosses >> G/D 0.832/0.694 D Real :0.729 D Fake :0.730\n",
      "Epoch 159 |  ET 36.26 min AvgLosses >> G/D 0.910/0.778 D Real :0.912 D Fake :0.878\n",
      "Epoch 160 |  ET 36.48 min AvgLosses >> G/D 0.602/0.954 D Real :0.891 D Fake :0.905\n",
      "Epoch 161 |  ET 36.71 min AvgLosses >> G/D 0.862/0.891 D Real :0.843 D Fake :0.865\n",
      "Epoch 162 |  ET 36.93 min AvgLosses >> G/D 0.559/0.642 D Real :0.762 D Fake :0.840\n",
      "Epoch 163 |  ET 37.15 min AvgLosses >> G/D 0.700/0.987 D Real :1.089 D Fake :0.669\n",
      "Epoch 164 |  ET 37.37 min AvgLosses >> G/D 0.942/0.864 D Real :0.951 D Fake :0.714\n",
      "Epoch 165 |  ET 37.59 min AvgLosses >> G/D 1.102/0.739 D Real :1.037 D Fake :0.983\n",
      "Epoch 166 |  ET 37.81 min AvgLosses >> G/D 0.868/1.080 D Real :1.019 D Fake :0.940\n",
      "Epoch 167 |  ET 38.03 min AvgLosses >> G/D 0.894/0.656 D Real :1.075 D Fake :0.969\n",
      "Epoch 168 |  ET 38.26 min AvgLosses >> G/D 0.848/0.661 D Real :0.863 D Fake :0.591\n",
      "Epoch 169 |  ET 38.48 min AvgLosses >> G/D 0.673/0.817 D Real :1.283 D Fake :0.651\n",
      "Epoch 170 |  ET 38.71 min AvgLosses >> G/D 0.982/0.944 D Real :0.647 D Fake :0.918\n",
      "Epoch 171 |  ET 38.94 min AvgLosses >> G/D 1.082/0.827 D Real :0.886 D Fake :1.021\n",
      "Epoch 172 |  ET 39.16 min AvgLosses >> G/D 0.713/0.761 D Real :0.874 D Fake :0.898\n",
      "Epoch 173 |  ET 39.39 min AvgLosses >> G/D 0.516/1.173 D Real :0.719 D Fake :0.943\n",
      "Saved checkpoint for step 176: log/GANClusterRemoval_Test/checkpoints\\ckpt-7\n",
      "Epoch 174 |  ET 39.61 min AvgLosses >> G/D 0.823/1.046 D Real :0.882 D Fake :0.839\n",
      "Epoch 175 |  ET 39.84 min AvgLosses >> G/D 0.952/0.838 D Real :0.653 D Fake :1.106\n",
      "Epoch 176 |  ET 40.06 min AvgLosses >> G/D 0.832/0.775 D Real :0.859 D Fake :0.787\n",
      "Epoch 177 |  ET 40.29 min AvgLosses >> G/D 0.907/0.856 D Real :0.778 D Fake :0.868\n",
      "Epoch 178 |  ET 40.51 min AvgLosses >> G/D 0.972/0.991 D Real :0.707 D Fake :0.617\n",
      "Epoch 179 |  ET 40.74 min AvgLosses >> G/D 0.970/0.837 D Real :0.642 D Fake :0.961\n",
      "Epoch 180 |  ET 40.96 min AvgLosses >> G/D 0.942/0.890 D Real :0.848 D Fake :0.613\n",
      "Epoch 181 |  ET 41.19 min AvgLosses >> G/D 1.051/0.852 D Real :0.753 D Fake :0.886\n",
      "Epoch 182 |  ET 41.41 min AvgLosses >> G/D 0.726/0.890 D Real :1.065 D Fake :0.847\n",
      "Epoch 183 |  ET 41.64 min AvgLosses >> G/D 0.722/0.854 D Real :0.993 D Fake :1.097\n",
      "Epoch 184 |  ET 41.87 min AvgLosses >> G/D 0.852/0.972 D Real :1.037 D Fake :0.921\n",
      "Epoch 185 |  ET 42.10 min AvgLosses >> G/D 0.943/0.918 D Real :0.646 D Fake :1.050\n",
      "Epoch 186 |  ET 42.33 min AvgLosses >> G/D 0.969/0.685 D Real :0.797 D Fake :0.789\n",
      "Epoch 187 |  ET 42.56 min AvgLosses >> G/D 1.080/0.858 D Real :0.885 D Fake :1.033\n",
      "Epoch 188 |  ET 42.78 min AvgLosses >> G/D 0.956/0.879 D Real :0.892 D Fake :1.104\n",
      "Epoch 189 |  ET 43.01 min AvgLosses >> G/D 0.889/0.870 D Real :0.733 D Fake :0.825\n",
      "Epoch 190 |  ET 43.24 min AvgLosses >> G/D 0.818/1.122 D Real :0.950 D Fake :1.172\n",
      "Epoch 191 |  ET 43.46 min AvgLosses >> G/D 0.890/0.759 D Real :0.732 D Fake :0.690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192 |  ET 43.69 min AvgLosses >> G/D 0.751/0.762 D Real :0.842 D Fake :0.807\n",
      "Epoch 193 |  ET 43.92 min AvgLosses >> G/D 1.091/0.959 D Real :0.715 D Fake :1.071\n",
      "Epoch 194 |  ET 44.14 min AvgLosses >> G/D 0.725/0.980 D Real :1.014 D Fake :0.655\n",
      "Epoch 195 |  ET 44.37 min AvgLosses >> G/D 0.847/0.970 D Real :0.884 D Fake :0.848\n",
      "Epoch 196 |  ET 44.59 min AvgLosses >> G/D 0.688/0.694 D Real :0.620 D Fake :0.750\n",
      "Epoch 197 |  ET 44.82 min AvgLosses >> G/D 0.844/0.787 D Real :0.939 D Fake :0.754\n",
      "Epoch 198 |  ET 45.05 min AvgLosses >> G/D 0.943/0.772 D Real :0.846 D Fake :1.001\n",
      "Saved checkpoint for step 201: log/GANClusterRemoval_Test/checkpoints\\ckpt-8\n",
      "Epoch 199 |  ET 45.28 min AvgLosses >> G/D 0.771/1.252 D Real :0.832 D Fake :0.657\n",
      "Epoch 200 |  ET 45.51 min AvgLosses >> G/D 0.973/0.812 D Real :0.870 D Fake :0.861\n",
      "Epoch 201 |  ET 45.74 min AvgLosses >> G/D 0.694/0.737 D Real :0.804 D Fake :0.887\n",
      "Epoch 202 |  ET 45.97 min AvgLosses >> G/D 0.683/0.949 D Real :0.763 D Fake :0.840\n",
      "Epoch 203 |  ET 46.20 min AvgLosses >> G/D 0.689/0.752 D Real :0.846 D Fake :0.664\n",
      "Epoch 204 |  ET 46.42 min AvgLosses >> G/D 0.706/1.116 D Real :0.798 D Fake :0.601\n",
      "Epoch 205 |  ET 46.65 min AvgLosses >> G/D 0.657/0.853 D Real :0.564 D Fake :0.895\n",
      "Epoch 206 |  ET 46.87 min AvgLosses >> G/D 0.833/0.701 D Real :0.892 D Fake :1.004\n",
      "Epoch 207 |  ET 47.09 min AvgLosses >> G/D 0.734/0.883 D Real :1.038 D Fake :0.916\n",
      "Epoch 208 |  ET 47.31 min AvgLosses >> G/D 1.105/0.810 D Real :0.729 D Fake :0.863\n",
      "Epoch 209 |  ET 47.53 min AvgLosses >> G/D 0.714/0.933 D Real :0.976 D Fake :1.043\n",
      "Epoch 210 |  ET 47.75 min AvgLosses >> G/D 0.720/0.852 D Real :0.856 D Fake :0.693\n",
      "Epoch 211 |  ET 47.97 min AvgLosses >> G/D 0.940/0.614 D Real :0.679 D Fake :0.766\n",
      "Epoch 212 |  ET 48.20 min AvgLosses >> G/D 0.859/1.205 D Real :0.856 D Fake :0.675\n",
      "Epoch 213 |  ET 48.43 min AvgLosses >> G/D 0.561/0.916 D Real :1.012 D Fake :0.875\n",
      "Epoch 214 |  ET 48.66 min AvgLosses >> G/D 0.805/0.644 D Real :1.391 D Fake :0.584\n",
      "Epoch 215 |  ET 48.88 min AvgLosses >> G/D 0.751/0.813 D Real :0.880 D Fake :0.670\n",
      "Epoch 216 |  ET 49.11 min AvgLosses >> G/D 0.815/0.876 D Real :0.848 D Fake :0.809\n",
      "Epoch 217 |  ET 49.34 min AvgLosses >> G/D 0.870/1.490 D Real :0.791 D Fake :1.042\n",
      "Epoch 218 |  ET 49.57 min AvgLosses >> G/D 1.031/0.717 D Real :0.780 D Fake :0.777\n",
      "Epoch 219 |  ET 49.80 min AvgLosses >> G/D 0.723/1.088 D Real :1.055 D Fake :0.743\n",
      "Epoch 220 |  ET 50.02 min AvgLosses >> G/D 1.128/0.776 D Real :0.918 D Fake :0.766\n",
      "Epoch 221 |  ET 50.25 min AvgLosses >> G/D 0.817/0.724 D Real :0.736 D Fake :0.833\n",
      "Epoch 222 |  ET 50.48 min AvgLosses >> G/D 0.801/0.525 D Real :0.875 D Fake :0.901\n",
      "Epoch 223 |  ET 50.70 min AvgLosses >> G/D 1.037/0.957 D Real :0.780 D Fake :0.586\n",
      "Saved checkpoint for step 226: log/GANClusterRemoval_Test/checkpoints\\ckpt-9\n",
      "Epoch 224 |  ET 50.93 min AvgLosses >> G/D 0.693/0.756 D Real :0.726 D Fake :0.651\n",
      "Epoch 225 |  ET 51.16 min AvgLosses >> G/D 0.930/0.901 D Real :0.763 D Fake :1.183\n",
      "Epoch 226 |  ET 51.40 min AvgLosses >> G/D 0.964/0.706 D Real :0.891 D Fake :0.839\n",
      "Epoch 227 |  ET 51.62 min AvgLosses >> G/D 0.783/0.610 D Real :0.572 D Fake :0.787\n",
      "Epoch 228 |  ET 51.85 min AvgLosses >> G/D 0.842/0.819 D Real :0.678 D Fake :1.009\n",
      "Epoch 229 |  ET 52.07 min AvgLosses >> G/D 0.779/0.942 D Real :0.721 D Fake :0.854\n",
      "Epoch 230 |  ET 52.30 min AvgLosses >> G/D 0.697/0.775 D Real :0.738 D Fake :0.728\n",
      "Epoch 231 |  ET 52.53 min AvgLosses >> G/D 0.856/0.709 D Real :0.759 D Fake :0.956\n",
      "Epoch 232 |  ET 52.75 min AvgLosses >> G/D 0.905/1.068 D Real :0.698 D Fake :0.731\n",
      "Epoch 233 |  ET 52.98 min AvgLosses >> G/D 0.642/0.668 D Real :1.134 D Fake :0.677\n",
      "Epoch 234 |  ET 53.21 min AvgLosses >> G/D 0.942/0.897 D Real :0.779 D Fake :0.585\n",
      "Epoch 235 |  ET 53.43 min AvgLosses >> G/D 0.661/1.025 D Real :0.992 D Fake :0.932\n",
      "Epoch 236 |  ET 53.66 min AvgLosses >> G/D 0.692/0.926 D Real :0.787 D Fake :0.898\n",
      "Epoch 237 |  ET 53.89 min AvgLosses >> G/D 0.664/0.795 D Real :1.036 D Fake :0.709\n",
      "Epoch 238 |  ET 54.12 min AvgLosses >> G/D 0.872/1.015 D Real :0.675 D Fake :0.734\n",
      "Epoch 239 |  ET 54.35 min AvgLosses >> G/D 0.912/0.648 D Real :0.688 D Fake :0.799\n",
      "Epoch 240 |  ET 54.58 min AvgLosses >> G/D 0.917/1.253 D Real :0.895 D Fake :0.970\n",
      "Epoch 241 |  ET 54.81 min AvgLosses >> G/D 0.743/0.676 D Real :0.938 D Fake :0.911\n",
      "Epoch 242 |  ET 55.03 min AvgLosses >> G/D 1.013/1.006 D Real :1.309 D Fake :0.918\n",
      "Epoch 243 |  ET 55.25 min AvgLosses >> G/D 1.080/0.861 D Real :0.716 D Fake :0.717\n",
      "Epoch 244 |  ET 55.47 min AvgLosses >> G/D 0.639/0.762 D Real :0.711 D Fake :0.933\n",
      "Epoch 245 |  ET 55.69 min AvgLosses >> G/D 0.950/0.708 D Real :0.934 D Fake :0.784\n",
      "Epoch 246 |  ET 55.91 min AvgLosses >> G/D 0.966/0.961 D Real :1.249 D Fake :0.912\n",
      "Epoch 247 |  ET 56.13 min AvgLosses >> G/D 0.987/0.778 D Real :0.793 D Fake :0.667\n",
      "Epoch 248 |  ET 56.35 min AvgLosses >> G/D 0.717/0.814 D Real :0.744 D Fake :0.970\n",
      "Saved checkpoint for step 251: log/GANClusterRemoval_Test/checkpoints\\ckpt-10\n",
      "Epoch 249 |  ET 56.56 min AvgLosses >> G/D 0.802/1.018 D Real :0.742 D Fake :0.742\n",
      "Epoch 250 |  ET 56.78 min AvgLosses >> G/D 0.764/0.915 D Real :0.903 D Fake :1.101\n",
      "Epoch 251 |  ET 56.99 min AvgLosses >> G/D 0.672/0.591 D Real :0.847 D Fake :0.671\n",
      "Epoch 252 |  ET 57.20 min AvgLosses >> G/D 0.822/0.951 D Real :0.943 D Fake :1.029\n",
      "Epoch 253 |  ET 57.42 min AvgLosses >> G/D 0.495/0.841 D Real :0.871 D Fake :0.825\n",
      "Epoch 254 |  ET 57.64 min AvgLosses >> G/D 0.824/1.044 D Real :1.039 D Fake :0.762\n",
      "Epoch 255 |  ET 57.86 min AvgLosses >> G/D 0.825/0.936 D Real :1.087 D Fake :0.905\n",
      "Epoch 256 |  ET 58.08 min AvgLosses >> G/D 1.251/0.998 D Real :0.854 D Fake :1.212\n",
      "Epoch 257 |  ET 58.31 min AvgLosses >> G/D 1.022/0.841 D Real :0.871 D Fake :0.761\n",
      "Epoch 258 |  ET 58.53 min AvgLosses >> G/D 0.766/0.588 D Real :0.720 D Fake :0.775\n",
      "Epoch 259 |  ET 58.75 min AvgLosses >> G/D 0.819/0.788 D Real :0.922 D Fake :0.742\n",
      "Epoch 260 |  ET 58.97 min AvgLosses >> G/D 0.956/0.847 D Real :0.774 D Fake :0.837\n",
      "Epoch 261 |  ET 59.18 min AvgLosses >> G/D 0.735/0.787 D Real :0.893 D Fake :0.899\n",
      "Epoch 262 |  ET 59.40 min AvgLosses >> G/D 0.798/0.729 D Real :0.649 D Fake :0.801\n",
      "Epoch 263 |  ET 59.61 min AvgLosses >> G/D 0.830/0.696 D Real :0.685 D Fake :0.897\n",
      "Epoch 264 |  ET 59.83 min AvgLosses >> G/D 0.953/0.984 D Real :0.580 D Fake :0.926\n",
      "Epoch 265 |  ET 60.05 min AvgLosses >> G/D 0.835/0.711 D Real :0.593 D Fake :0.877\n",
      "Epoch 266 |  ET 60.27 min AvgLosses >> G/D 0.629/0.750 D Real :0.742 D Fake :0.851\n",
      "Epoch 267 |  ET 60.50 min AvgLosses >> G/D 1.060/0.735 D Real :0.739 D Fake :0.965\n",
      "Epoch 268 |  ET 60.72 min AvgLosses >> G/D 1.093/0.952 D Real :0.778 D Fake :0.875\n",
      "Epoch 269 |  ET 60.94 min AvgLosses >> G/D 1.138/0.830 D Real :0.939 D Fake :0.880\n",
      "Epoch 270 |  ET 61.17 min AvgLosses >> G/D 1.009/0.946 D Real :0.623 D Fake :0.799\n",
      "Epoch 271 |  ET 61.39 min AvgLosses >> G/D 0.695/1.104 D Real :0.783 D Fake :0.790\n",
      "Epoch 272 |  ET 61.62 min AvgLosses >> G/D 0.918/0.603 D Real :0.830 D Fake :0.647\n",
      "Epoch 273 |  ET 61.84 min AvgLosses >> G/D 0.765/0.662 D Real :0.781 D Fake :0.827\n",
      "Saved checkpoint for step 276: log/GANClusterRemoval_Test/checkpoints\\ckpt-11\n",
      "Epoch 274 |  ET 62.07 min AvgLosses >> G/D 1.088/0.697 D Real :1.032 D Fake :1.131\n",
      "Epoch 275 |  ET 62.30 min AvgLosses >> G/D 0.648/1.015 D Real :0.693 D Fake :0.867\n",
      "Epoch 276 |  ET 62.53 min AvgLosses >> G/D 0.886/0.814 D Real :0.484 D Fake :1.235\n",
      "Epoch 277 |  ET 62.76 min AvgLosses >> G/D 0.944/0.969 D Real :0.760 D Fake :0.765\n",
      "Epoch 278 |  ET 62.98 min AvgLosses >> G/D 0.878/0.883 D Real :0.587 D Fake :0.792\n",
      "Epoch 279 |  ET 63.21 min AvgLosses >> G/D 0.697/0.810 D Real :1.101 D Fake :1.027\n",
      "Epoch 280 |  ET 63.44 min AvgLosses >> G/D 0.982/0.866 D Real :0.754 D Fake :0.993\n",
      "Epoch 281 |  ET 63.67 min AvgLosses >> G/D 1.027/0.906 D Real :0.629 D Fake :0.889\n",
      "Epoch 282 |  ET 63.89 min AvgLosses >> G/D 0.953/1.169 D Real :1.006 D Fake :1.189\n",
      "Epoch 283 |  ET 64.12 min AvgLosses >> G/D 0.650/0.756 D Real :0.636 D Fake :1.368\n",
      "Epoch 284 |  ET 64.35 min AvgLosses >> G/D 0.884/0.784 D Real :0.741 D Fake :0.879\n",
      "Epoch 285 |  ET 64.58 min AvgLosses >> G/D 0.801/0.874 D Real :0.622 D Fake :0.696\n",
      "Epoch 286 |  ET 64.81 min AvgLosses >> G/D 0.950/0.813 D Real :0.981 D Fake :0.942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287 |  ET 65.03 min AvgLosses >> G/D 0.961/0.939 D Real :1.152 D Fake :0.842\n",
      "Epoch 288 |  ET 65.25 min AvgLosses >> G/D 0.716/0.764 D Real :1.011 D Fake :0.643\n",
      "Epoch 289 |  ET 65.48 min AvgLosses >> G/D 0.817/0.631 D Real :0.895 D Fake :0.931\n",
      "Epoch 290 |  ET 65.70 min AvgLosses >> G/D 0.761/0.818 D Real :1.289 D Fake :0.719\n",
      "Epoch 291 |  ET 65.92 min AvgLosses >> G/D 0.796/0.797 D Real :0.827 D Fake :0.671\n",
      "Epoch 292 |  ET 66.14 min AvgLosses >> G/D 1.043/1.115 D Real :1.036 D Fake :0.669\n",
      "Epoch 293 |  ET 66.36 min AvgLosses >> G/D 0.766/0.674 D Real :0.770 D Fake :0.729\n",
      "Epoch 294 |  ET 66.58 min AvgLosses >> G/D 1.083/0.785 D Real :0.890 D Fake :0.734\n",
      "Epoch 295 |  ET 66.81 min AvgLosses >> G/D 0.735/0.967 D Real :0.942 D Fake :0.848\n",
      "Epoch 296 |  ET 67.03 min AvgLosses >> G/D 0.732/0.760 D Real :0.934 D Fake :0.850\n",
      "Epoch 297 |  ET 67.27 min AvgLosses >> G/D 0.941/0.883 D Real :0.838 D Fake :0.915\n",
      "Epoch 298 |  ET 67.50 min AvgLosses >> G/D 0.789/1.150 D Real :0.791 D Fake :0.803\n",
      "Saved checkpoint for step 301: log/GANClusterRemoval_Test/checkpoints\\ckpt-12\n",
      "Epoch 299 |  ET 67.72 min AvgLosses >> G/D 0.845/0.798 D Real :0.730 D Fake :0.932\n"
     ]
    }
   ],
   "source": [
    "gen_model, disc_model, ds_train = init_model(X_train ,y_train, batch=settings['batch'], zIn=settings['input_size'], \n",
    "                                             g_layers = settings['gen_layers'], g_size=settings['gen_size'], \n",
    "                                             d_layers = settings['disc_layers'],d_size=settings['disc_size'],\n",
    "                                             zmode=settings['input_dist'], discDrop=settings['disc_dropOut'])\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "g_optimizer = tf.keras.optimizers.Adam(settings['Adam_gen_rate'])\n",
    "d_optimizer = tf.keras.optimizers.Adam(settings['Adam_disc_rate'])\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=g_optimizer,discriminator_optimizer=d_optimizer,\n",
    "                             generator=gen_model,discriminator=disc_model,step=tf.Variable(1))\n",
    "\n",
    "cpD = settings['CheckPointDirec']\n",
    "checkpointDirec = f'{base_folder}{cpD}'\n",
    "\n",
    "manager = tf.train.CheckpointManager(checkpoint,checkpointDirec, max_to_keep=settings['CheckPointsKeep'])\n",
    "epoch_losses = []\n",
    "all_losses = []\n",
    "all_d_vals = []\n",
    "train(ds_train,settings['epochs'],manager,settings['batch'],settings['input_size'])\n",
    "\n",
    "outName = f'{nameRun[1:]}'\n",
    "saveNetwork_Scaler(gen_model, disc_model, mm, outName, direc=f'{base_folder}')\n",
    "\n",
    "if saveLoss:\n",
    "    name = f'loss_{nameRun[1:]}'\n",
    "    saveTrainLoss(all_losses,all_d_vals,name,direc=f'{base_folder}/loss/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4de56acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import LoopEndpoints as le\n",
    "import GenerateEndpoints as ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "32c55f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_name = 'log/GANClusterRemoval_Test/lusterRemoval_Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "03abb1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structures Generation Attempts: 32\n",
      "MSE for recon is 0.10 Angstroms\n",
      "Elapsed time: 0.76\n",
      "0.02s per structure\n",
      "No Clash Structures: 8\n",
      "Two Atoms or less Clash Structures: 23\n",
      "Clashed Atoms Mean: 1.81 +/- 1.26\n",
      "Percent Core: 0.13 +/- 0.06\n",
      " \n",
      " \n",
      "cycle: 0\n",
      "first helix: #1\n",
      "first loop: #9\n",
      "second helix: #0\n",
      "fail\n",
      "first helix: #1\n",
      "first loop: #24\n",
      "second helix: #1\n",
      "fail2\n",
      "first helix: #1\n",
      "first loop: #10\n",
      "second helix: #0\n",
      "fail\n",
      "first helix: #1\n",
      "first loop: #17\n",
      "second helix: #0\n",
      "fail\n",
      "first helix: #1\n",
      "first loop: #20\n",
      "second helix: #1\n",
      "fail2\n",
      "first helix: #1\n",
      "first loop: #24\n",
      "second helix: #0\n",
      "fail\n",
      "first helix: #1\n",
      "first loop: #25\n",
      "second helix: #0\n",
      "fail\n",
      "first helix: #1\n",
      "first loop: #26\n",
      "second helix: #0\n",
      "fail\n",
      "first helix: #1\n",
      "first loop: #19\n",
      "second helix: #0\n",
      "fail\n",
      "first helix: #1\n",
      "first loop: #25\n",
      "second helix: #3\n",
      "3 helix: #11\n",
      "4 helix: #35\n",
      "Num_Structs9x:    21\n",
      "first helix: #1\n",
      "first loop: #18\n",
      "second helix: #0\n",
      "fail\n",
      "first helix: #1\n",
      "first loop: #23\n",
      "second helix: #12\n",
      "3 helix: #9\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs11x:    15\n",
      "first helix: #1\n",
      "first loop: #9\n",
      "second helix: #1\n",
      "3 helix: #2\n",
      "4 helix: #12\n",
      "Num_Structs12x:    9\n",
      "first helix: #1\n",
      "first loop: #19\n",
      "second helix: #0\n",
      "fail\n",
      "first helix: #1\n",
      "first loop: #13\n",
      "second helix: #8\n",
      "3 helix: #1\n",
      "fail2\n",
      "first helix: #1\n",
      "first loop: #23\n",
      "second helix: #7\n",
      "3 helix: #5\n",
      "4 helix: #6\n",
      "Num_Structs15x:    4\n",
      "first helix: #1\n",
      "first loop: #29\n",
      "second helix: #3\n",
      "fail2\n",
      "first helix: #1\n",
      "first loop: #18\n",
      "second helix: #0\n",
      "fail\n",
      "first helix: #1\n",
      "first loop: #17\n",
      "second helix: #3\n",
      "fail2\n",
      "first helix: #1\n",
      "first loop: #18\n",
      "second helix: #1\n",
      "fail2\n",
      "first helix: #1\n",
      "first loop: #28\n",
      "second helix: #3\n",
      "fail2\n",
      "first helix: #1\n",
      "first loop: #23\n",
      "second helix: #0\n",
      "fail\n",
      "first helix: #1\n",
      "first loop: #12\n",
      "second helix: #0\n",
      "fail\n",
      "first helix: #1\n",
      "first loop: #23\n",
      "second helix: #0\n",
      "fail\n",
      "first helix: #1\n",
      "first loop: #25\n",
      "second helix: #5\n",
      "3 helix: #15\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs24x:    12\n",
      "first helix: #1\n",
      "first loop: #25\n",
      "second helix: #1\n",
      "3 helix: #7\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs25x:    11\n",
      "first helix: #1\n",
      "first loop: #24\n",
      "second helix: #0\n",
      "fail\n",
      "first helix: #1\n",
      "first loop: #20\n",
      "second helix: #10\n",
      "3 helix: #21\n",
      "4 helix: #39\n",
      "Num_Structs27x:    23\n",
      "first helix: #1\n",
      "first loop: #25\n",
      "second helix: #8\n",
      "fail2\n",
      "first helix: #1\n",
      "first loop: #22\n",
      "second helix: #4\n",
      "3 helix: #12\n",
      "4 helix: #5\n",
      "Num_Structs29x:    4\n",
      "first helix: #1\n",
      "first loop: #16\n",
      "second helix: #3\n",
      "3 helix: #1\n",
      "4 helix: #4\n",
      "Num_Structs30x:    3\n",
      "first helix: #1\n",
      "first loop: #19\n",
      "second helix: #0\n",
      "fail\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "cycle: 1\n",
      "first helix: #3\n",
      "first loop: #34\n",
      "second helix: #5\n",
      "fail2\n",
      "first helix: #3\n",
      "first loop: #71\n",
      "second helix: #55\n",
      "3 helix: reduced to #20\n",
      "3 helix: #20\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs1x:    15\n",
      "first helix: #3\n",
      "first loop: #30\n",
      "second helix: #4\n",
      "3 helix: #3\n",
      "4 helix: #4\n",
      "Num_Structs2x:    2\n",
      "first helix: #3\n",
      "first loop: #50\n",
      "second helix: #18\n",
      "3 helix: #28\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs3x:    16\n",
      "first helix: #3\n",
      "first loop: #58\n",
      "second helix: #20\n",
      "fail2\n",
      "first helix: #3\n",
      "first loop: #71\n",
      "second helix: #23\n",
      "3 helix: reduced to #20\n",
      "3 helix: #20\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs5x:    17\n",
      "first helix: #3\n",
      "first loop: #75\n",
      "second helix: #58\n",
      "3 helix: reduced to #20\n",
      "3 helix: #20\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs6x:    9\n",
      "first helix: #3\n",
      "first loop: #68\n",
      "second helix: #32\n",
      "fail2\n",
      "first helix: #3\n",
      "first loop: #56\n",
      "second helix: #8\n",
      "fail2\n",
      "first helix: #3\n",
      "first loop: #51\n",
      "second helix: #15\n",
      "3 helix: reduced to #20\n",
      "3 helix: #20\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs10x:    16\n",
      "first helix: #3\n",
      "first loop: #61\n",
      "second helix: #15\n",
      "3 helix: #4\n",
      "fail2\n",
      "first helix: #3\n",
      "first loop: #34\n",
      "second helix: #32\n",
      "3 helix: reduced to #20\n",
      "3 helix: #20\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs14x:    13\n",
      "first helix: #3\n",
      "first loop: #76\n",
      "second helix: #30\n",
      "3 helix: reduced to #20\n",
      "3 helix: #20\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs16x:    15\n",
      "first helix: #3\n",
      "first loop: #50\n",
      "second helix: #19\n",
      "3 helix: #20\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs17x:    14\n",
      "first helix: #3\n",
      "first loop: #51\n",
      "second helix: #19\n",
      "3 helix: #20\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs18x:    10\n",
      "first helix: #3\n",
      "first loop: #46\n",
      "second helix: #2\n",
      "fail2\n",
      "first helix: #3\n",
      "first loop: #71\n",
      "second helix: #29\n",
      "3 helix: #8\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs20x:    13\n",
      "first helix: #3\n",
      "first loop: #71\n",
      "second helix: #47\n",
      "3 helix: reduced to #20\n",
      "3 helix: #20\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs21x:    17\n",
      "first helix: #3\n",
      "first loop: #35\n",
      "second helix: #0\n",
      "fail\n",
      "first helix: #3\n",
      "first loop: #65\n",
      "second helix: #23\n",
      "3 helix: reduced to #20\n",
      "3 helix: #20\n",
      "4 helix: #39\n",
      "Num_Structs23x:    10\n",
      "first helix: #3\n",
      "first loop: #63\n",
      "second helix: #0\n",
      "fail\n",
      "first helix: #3\n",
      "first loop: #67\n",
      "second helix: #25\n",
      "fail2\n",
      "first helix: #3\n",
      "first loop: #56\n",
      "second helix: #21\n",
      "3 helix: #21\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs31x:    15\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "cycle: 2\n",
      "first helix: #5\n",
      "first loop: #97\n",
      "second helix: #16\n",
      "3 helix: #33\n",
      "4 helix: #12\n",
      "Num_Structs0x:    4\n",
      "first helix: #5\n",
      "first loop: #153\n",
      "second helix: #68\n",
      "3 helix: reduced to #20\n",
      "3 helix: #20\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs4x:    13\n",
      "first helix: #5\n",
      "first loop: #185\n",
      "second helix: #157\n",
      "3 helix: reduced to #20\n",
      "3 helix: #20\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs7x:    12\n",
      "first helix: #5\n",
      "first loop: #161\n",
      "second helix: #102\n",
      "3 helix: reduced to #20\n",
      "3 helix: #20\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs8x:    14\n",
      "first helix: #5\n",
      "first loop: #170\n",
      "second helix: #141\n",
      "3 helix: reduced to #20\n",
      "3 helix: #20\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs13x:    16\n",
      "first helix: #5\n",
      "first loop: #127\n",
      "second helix: #71\n",
      "3 helix: reduced to #20\n",
      "3 helix: #20\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs19x:    14\n",
      "first helix: #5\n",
      "first loop: #87\n",
      "second helix: #22\n",
      "3 helix: reduced to #20\n",
      "3 helix: #20\n",
      "4 helix: #20\n",
      "Num_Structs22x:    10\n",
      "first helix: #5\n",
      "first loop: #190\n",
      "second helix: #5\n",
      "3 helix: reduced to #20\n",
      "3 helix: #20\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs26x:    13\n",
      "first helix: #5\n",
      "first loop: #175\n",
      "second helix: #86\n",
      "3 helix: #21\n",
      "4 helix: reduced to #20\n",
      "4 helix: #20\n",
      "Num_Structs28x:    14\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "cycle: 3\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "cycle: 4\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "cycle: 5\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "cycle: 6\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "cycle: 7\n",
      "\n",
      "\n",
      "Elapsed time: 22.25\n",
      "Unique Structures: 32   Unique Phis: 394\n",
      "0.06s per structure\n",
      "Loop Success: 32. Phi Reduced Structures: 394\n",
      "Total time: 22.25\n",
      "Time Per Unique Topology: 0.70s\n",
      "Time Per Phi Bins Struct: 0.06s\n"
     ]
    }
   ],
   "source": [
    "le.bb_analyze('log/GANClusterRemoval_Test/lusterRemoval_Test',batch=32,z=12,analysisOnly=True,\n",
    "               outDirec='output/', print_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50b9c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "br = ge.BatchRecon(name=gen_name)\n",
    "br.generate(12,batch_size=32)\n",
    "endpoint_list = br.MDS_reconstruct_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "275ea80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = ge.BatchRecon(name='data/BestGenerator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "db8a0b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.316128 , 16.554947 , 16.334831 , 18.457684 , 16.125488 ,\n",
       "        19.339027 , 21.109901 ,  9.20863  , 26.600903 , 27.636366 ,\n",
       "        12.6324415, 13.341254 , 23.701595 , 21.998808 , 21.299803 ,\n",
       "        14.397279 ,  8.573537 , 15.080368 , 12.149821 , 27.943943 ,\n",
       "        26.60883  , 18.371593 , 24.672335 , 21.73369  , 11.703793 ,\n",
       "        10.7223015, 22.248615 , 15.062401 ],\n",
       "       [18.086597 , 19.779205 , 15.041035 ,  9.039525 , 24.438576 ,\n",
       "        22.060396 , 11.169869 ,  6.098048 , 26.44907  , 22.686506 ,\n",
       "        17.181595 , 11.940178 , 18.924473 , 24.58757  , 22.94601  ,\n",
       "        14.365549 , 10.581507 , 21.758982 , 10.608971 , 26.232204 ,\n",
       "        27.723244 , 22.20776  , 23.262676 , 22.763758 , 11.990326 ,\n",
       "         8.342196 , 20.643728 , 17.093775 ],\n",
       "       [20.920176 , 18.241219 , 14.887065 , 18.552011 , 22.265125 ,\n",
       "        15.801541 ,  9.991272 , 10.577459 , 29.845781 , 26.438082 ,\n",
       "        16.89434  , 13.016779 , 25.473948 , 22.265509 , 17.461037 ,\n",
       "        19.032284 , 14.674202 , 21.478008 , 11.448679 , 29.109877 ,\n",
       "        24.369503 , 11.165801 , 24.539244 , 21.640104 , 16.344284 ,\n",
       "         9.544155 , 19.069532 , 15.796917 ],\n",
       "       [18.79881  , 18.701473 , 22.994093 , 19.933832 , 27.430138 ,\n",
       "        22.089437 , 11.689993 ,  6.702912 , 28.72082  , 25.546928 ,\n",
       "        11.827957 , 10.360597 , 20.064558 , 23.164448 , 21.662485 ,\n",
       "        11.113714 , 12.972022 , 18.202297 ,  9.089789 , 27.665558 ,\n",
       "        28.595844 , 14.578828 , 23.891708 , 22.374727 ,  9.391504 ,\n",
       "        10.939843 , 23.642405 , 19.115097 ],\n",
       "       [17.248755 , 16.631264 , 13.815424 , 20.580008 , 21.354988 ,\n",
       "        17.062061 ,  7.8429813, 10.950404 , 27.050562 , 30.658644 ,\n",
       "        17.155128 , 15.870542 , 22.52272  , 21.351673 , 22.763382 ,\n",
       "        10.927393 , 11.204557 , 19.336565 ,  9.3011675, 25.930243 ,\n",
       "        24.149921 , 12.136176 , 23.978481 , 23.963423 , 16.198467 ,\n",
       "         6.8349276, 20.446453 , 16.631687 ],\n",
       "       [19.82762  , 17.366732 , 17.438522 , 15.964088 , 25.925564 ,\n",
       "        14.432863 ,  9.40051  , 10.046186 , 27.742031 , 28.565884 ,\n",
       "        22.380957 , 16.203712 , 29.593843 , 20.96147  , 20.783676 ,\n",
       "        14.5297165,  9.19204  , 24.385647 ,  8.16397  , 25.79376  ,\n",
       "        21.419542 , 13.642138 , 22.501642 , 18.552519 ,  9.586599 ,\n",
       "        11.51597  , 26.545385 , 18.700989 ],\n",
       "       [15.598597 , 15.229774 , 14.807539 , 14.063063 , 18.08279  ,\n",
       "        19.333914 , 17.396675 ,  8.749974 , 27.21555  , 26.188843 ,\n",
       "        14.131679 , 12.050105 , 21.8708   , 22.278713 , 21.505123 ,\n",
       "        16.7762   ,  9.279125 , 14.954476 ,  8.777427 , 29.57935  ,\n",
       "        27.326601 , 15.846454 , 24.388306 , 22.83931  , 11.696005 ,\n",
       "        12.079346 , 21.661263 , 15.393203 ],\n",
       "       [16.157185 , 16.557156 , 16.682852 , 17.528751 , 23.921757 ,\n",
       "        22.765198 , 10.770814 , 10.105132 , 26.23813  , 23.574167 ,\n",
       "        16.285168 , 12.704573 , 14.374563 , 23.861328 , 24.749807 ,\n",
       "        12.865278 , 17.195013 , 18.138096 ,  8.791534 , 24.923481 ,\n",
       "        26.377253 , 16.901186 , 22.350489 , 20.65193  , 11.601966 ,\n",
       "        10.892867 , 19.671017 , 15.542152 ],\n",
       "       [18.911772 , 17.538536 , 25.3256   , 18.414745 , 28.353418 ,\n",
       "        19.963474 , 14.55932  ,  8.682006 , 28.187374 , 23.811579 ,\n",
       "        14.277038 ,  9.713978 , 21.705853 , 25.31547  , 22.45583  ,\n",
       "        17.614254 , 12.048275 , 21.233442 ,  9.675991 , 24.341715 ,\n",
       "        25.15592  , 23.986414 , 23.597286 , 20.678364 , 10.756524 ,\n",
       "        10.287304 , 22.36838  , 15.723661 ],\n",
       "       [18.348877 , 15.446349 , 16.763006 ,  9.404702 , 22.275087 ,\n",
       "        20.534058 ,  7.163304 , 12.135881 , 28.828411 , 26.428946 ,\n",
       "        22.256603 , 15.696228 , 21.338018 , 22.286242 , 19.714363 ,\n",
       "        12.2857065,  9.254677 , 16.937597 ,  9.762207 , 27.420418 ,\n",
       "        30.087275 , 23.352465 , 23.627352 , 24.696592 , 10.89889  ,\n",
       "         9.521378 , 21.212547 , 18.727331 ],\n",
       "       [16.193455 , 14.905739 , 16.884497 , 21.40083  , 20.058893 ,\n",
       "        16.921766 , 11.054605 ,  9.225664 , 28.25124  , 26.961443 ,\n",
       "        10.762782 , 11.4937935, 22.362091 , 21.799084 , 19.73831  ,\n",
       "        13.304389 , 15.217817 , 19.570995 , 10.397988 , 27.890537 ,\n",
       "        26.702024 , 11.559443 , 23.88938  , 24.81956  , 14.6195755,\n",
       "         7.219026 , 21.450418 , 17.944426 ],\n",
       "       [22.213018 , 19.747097 , 11.746019 , 18.65909  , 28.746841 ,\n",
       "        23.530226 , 13.47576  , 12.2643795, 25.689949 , 26.661182 ,\n",
       "        14.232655 ,  7.2117095, 19.279696 , 21.25222  , 18.990534 ,\n",
       "        16.626465 , 11.748772 , 19.165897 , 10.6536455, 26.268972 ,\n",
       "        23.867886 ,  8.645714 , 23.610462 , 22.124489 , 12.808727 ,\n",
       "        10.245461 , 19.598473 , 15.605349 ],\n",
       "       [17.28353  , 21.876928 , 13.345777 , 10.767402 , 23.97418  ,\n",
       "        19.341312 ,  9.916226 , 10.02696  , 25.886505 , 24.087402 ,\n",
       "        17.835083 , 12.95251  , 20.113018 , 25.71027  , 25.402632 ,\n",
       "        11.438004 , 12.494729 , 25.414148 ,  9.537782 , 24.774616 ,\n",
       "        24.491243 , 18.862734 , 22.962442 , 20.590706 , 11.143292 ,\n",
       "         8.540312 , 22.579077 , 16.656303 ],\n",
       "       [21.240751 , 16.416098 , 21.532297 ,  8.928781 , 23.00807  ,\n",
       "        23.51711  , 24.348104 , 12.969246 , 27.061663 , 22.641808 ,\n",
       "        12.486441 ,  8.187843 , 22.195559 , 19.657087 , 16.293282 ,\n",
       "        20.999266 , 14.397372 , 18.223845 , 12.943464 , 23.534782 ,\n",
       "        21.394726 , 10.050696 , 22.164469 , 21.418673 , 19.809216 ,\n",
       "        11.224994 , 15.935316 , 13.833744 ],\n",
       "       [18.048815 , 18.808279 , 15.321561 ,  9.950817 , 25.550386 ,\n",
       "        20.97316  , 11.655748 ,  8.479119 , 28.755226 , 21.845682 ,\n",
       "        19.689638 , 10.293906 , 17.688328 , 25.123142 , 21.673027 ,\n",
       "        16.978718 , 10.480639 , 22.093475 , 10.716325 , 27.070023 ,\n",
       "        27.097906 , 20.776133 , 23.213966 , 21.392807 , 10.1218405,\n",
       "         9.134508 , 22.416834 , 17.863436 ],\n",
       "       [18.244783 , 17.07007  , 15.82432  ,  8.882542 , 24.932936 ,\n",
       "        20.93557  ,  7.733417 ,  9.929186 , 28.130869 , 26.53817  ,\n",
       "        25.885963 , 18.76059  , 17.643858 , 23.8673   , 22.428226 ,\n",
       "        17.439875 , 10.217518 , 15.981733 ,  9.974597 , 25.501585 ,\n",
       "        25.488737 , 22.061144 , 23.52213  , 22.730555 , 12.254613 ,\n",
       "         8.209313 , 21.114527 , 17.387024 ],\n",
       "       [14.100164 , 15.898506 , 13.899245 ,  8.386782 , 20.06546  ,\n",
       "        17.949017 , 15.208446 ,  8.622398 , 25.165422 , 20.38952  ,\n",
       "        15.515435 ,  8.325308 , 19.815939 , 23.329926 , 21.039375 ,\n",
       "        12.350071 , 11.913413 , 26.484222 , 10.616367 , 26.382105 ,\n",
       "        29.24127  , 25.257942 , 23.1496   , 23.495045 , 13.569035 ,\n",
       "        12.285831 , 22.011934 , 18.147207 ],\n",
       "       [16.819628 , 17.903606 , 15.4340925, 11.061181 , 20.32704  ,\n",
       "        23.120186 , 19.67536  , 10.364913 , 26.930153 , 23.333412 ,\n",
       "        10.427405 ,  9.807028 , 18.870852 , 22.63535  , 21.951483 ,\n",
       "        17.759619 , 12.612445 , 15.022999 ,  7.653224 , 29.027912 ,\n",
       "        28.831598 , 17.990545 , 24.926296 , 26.471508 , 17.470648 ,\n",
       "         9.578066 , 18.209068 , 15.522404 ],\n",
       "       [21.364305 , 16.379309 , 16.130125 , 19.472275 , 22.939173 ,\n",
       "        15.45629  , 18.10762  , 12.273867 , 28.958317 , 24.017296 ,\n",
       "        11.061402 , 11.451962 , 28.140009 , 20.940619 , 17.148155 ,\n",
       "        18.660831 , 14.019728 , 23.749235 , 11.9666605, 27.518053 ,\n",
       "        21.066149 ,  8.026923 , 23.268501 , 19.87095  , 11.155496 ,\n",
       "        12.124219 , 19.611954 , 16.200228 ],\n",
       "       [18.244808 , 15.85792  , 17.240303 , 14.057972 , 16.304895 ,\n",
       "        18.60812  , 19.68894  ,  9.554428 , 29.60953  , 28.521103 ,\n",
       "        12.039551 ,  9.420094 , 23.330887 , 22.175926 , 23.748629 ,\n",
       "        18.55968  , 15.160172 , 17.349674 ,  7.222572 , 26.69206  ,\n",
       "        27.379892 , 12.209742 , 24.119717 , 26.258003 , 15.836282 ,\n",
       "         6.5003037, 21.493902 , 19.856968 ],\n",
       "       [18.352053 , 22.608137 , 26.009851 , 18.965923 , 11.305796 ,\n",
       "        17.928263 , 25.794342 ,  5.8115892, 25.714506 , 22.289843 ,\n",
       "        13.894813 , 16.242897 , 14.055664 , 25.27546  , 24.688023 ,\n",
       "        18.015175 , 21.331741 , 13.5885515, 11.225194 , 29.145712 ,\n",
       "        25.555971 , 16.769026 , 21.697906 , 18.101952 , 19.014187 ,\n",
       "         9.412491 , 22.991186 , 20.582613 ],\n",
       "       [17.203247 , 16.069014 , 20.825005 , 12.73667  , 16.490322 ,\n",
       "        16.311205 , 16.961449 ,  7.480938 , 26.538616 , 26.11638  ,\n",
       "        16.9432   , 12.986715 , 19.82853  , 21.410112 , 21.954527 ,\n",
       "        17.375458 , 12.060584 , 14.3129225,  8.017222 , 32.585682 ,\n",
       "        28.481548 , 15.95299  , 28.60162  , 25.908697 , 14.653026 ,\n",
       "        10.0708275, 20.306452 , 13.786036 ],\n",
       "       [20.945927 , 19.14373  , 11.987625 , 16.355902 , 23.216799 ,\n",
       "        18.990782 ,  7.819634 , 11.296653 , 28.600437 , 29.579723 ,\n",
       "        10.687287 , 10.213805 , 20.72331  , 22.736065 , 23.631    ,\n",
       "        13.661071 , 15.467179 , 19.756437 ,  7.941283 , 28.338055 ,\n",
       "        25.582186 , 12.755871 , 26.443115 , 24.497066 , 12.690656 ,\n",
       "         7.9374495, 19.639381 , 14.66801  ],\n",
       "       [16.165314 , 15.766547 , 16.054873 , 16.620302 , 20.612286 ,\n",
       "        15.581066 ,  8.001398 ,  8.597687 , 28.552788 , 28.482986 ,\n",
       "        11.272843 , 14.227884 , 21.648336 , 23.514454 , 23.367105 ,\n",
       "        11.749628 , 16.899345 , 19.593365 ,  9.513189 , 31.140915 ,\n",
       "        28.400835 , 13.475032 , 27.042383 , 23.905638 , 10.140526 ,\n",
       "        11.355392 , 22.38322  , 16.33002  ]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf.generate(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "df487fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = endpoint_list[0][3]\n",
    "p2 =endpoint_list[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0b5a48a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09320673341737556"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(p2-p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cbbf48f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-e1a0adeec632>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_npose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\hTest\\HelixGen\\GenerateEndpoints.py\u001b[0m in \u001b[0;36mto_npose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhelixLength_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreconsMDS_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m                 \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mep_to_xform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreconsMDS_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreconsMDS_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhelixLength_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                 \u001b[0mapList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapList\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\hTest\\HelixGen\\GenerateEndpoints.py\u001b[0m in \u001b[0;36mep_to_xform\u001b[1;34m(p1, p2)\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0maRot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxisRot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m             \u001b[0mmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhalfLen\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp2\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "br.to_npose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5ab9b039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.45388815, -0.39153424, -0.5654259 , -0.29602832,  0.10598585,\n",
       "        -0.34222355, -0.49578336,  0.2950252 , -0.03136964,  0.27067   ,\n",
       "        -0.14823505, -0.40482584,  0.21652366, -0.06708521, -0.1749794 ,\n",
       "        -0.61948335, -0.43025467,  0.1311989 ,  0.3221391 ,  0.5648815 ,\n",
       "         0.3677734 , -0.10408167,  0.37132198,  0.35714194, -0.3694754 ,\n",
       "         0.05001154, -0.05818842, -0.08190887],\n",
       "       [ 0.5215131 ,  0.533925  , -0.67488575, -0.05551006, -0.00966968,\n",
       "         0.559437  ,  0.8130951 , -0.45586276, -0.44811082, -0.20689699,\n",
       "        -0.22735685, -0.42638406, -0.23950315, -0.25444758, -0.2390385 ,\n",
       "         0.09110764, -0.17467953, -0.33338562,  0.05443709, -0.3207543 ,\n",
       "         0.07227753,  0.19207914, -0.14749111, -0.17264353, -0.59601164,\n",
       "        -0.00590914,  0.3115075 ,  0.02066375],\n",
       "       [ 0.11670186, -0.23603064, -0.31616   , -0.20768537, -0.36390665,\n",
       "        -0.11516646,  0.42604345,  0.0313697 ,  0.24065383,  0.4387496 ,\n",
       "        -0.06719489, -0.2592178 ,  0.11691558, -0.17680377, -0.11237783,\n",
       "         0.00954331, -0.44608587, -0.4538957 , -0.3184815 ,  0.27704608,\n",
       "         0.22794582,  0.10017364,  0.28654593,  0.13129142, -0.36594087,\n",
       "         0.07970136,  0.20185125,  0.02421359],\n",
       "       [ 0.01798741, -0.42239672, -0.04219924,  0.14341623, -0.47388172,\n",
       "        -0.27434084,  0.631511  , -0.46517503,  0.37849286,  0.7084425 ,\n",
       "         0.10932174, -0.3895988 ,  0.5362166 , -0.0456806 ,  0.48025122,\n",
       "         0.13880146, -0.4985107 ,  0.18353517, -0.64773536, -0.19858934,\n",
       "        -0.23976259, -0.57196116,  0.272474  ,  0.13153072, -0.59726286,\n",
       "         0.5832374 ,  0.6178702 ,  0.31228226],\n",
       "       [ 0.19391745, -0.06708402, -0.48386857,  0.32375878,  0.6187927 ,\n",
       "         0.53946114, -0.40923545,  0.16773304, -0.18455122,  0.22459224,\n",
       "        -0.35427254, -0.6996752 , -0.31208467, -0.13220264, -0.06484433,\n",
       "         0.1446954 , -0.00161347, -0.06520168,  0.13779426,  0.17810237,\n",
       "         0.11295451, -0.5194991 ,  0.33838055,  0.49209327, -0.06175986,\n",
       "        -0.62028015, -0.08740219,  0.10873926],\n",
       "       [ 0.02922684, -0.16904671, -0.24190791, -0.0663586 , -0.30794886,\n",
       "         0.18376395,  0.29265022, -0.11860722,  0.38689038,  0.26952955,\n",
       "        -0.36103988, -0.30278486, -0.33282438,  0.10017282,  0.09893076,\n",
       "         0.00435278,  0.08575743, -0.599349  , -0.17005457,  0.13561074,\n",
       "         0.47893503,  0.11915725,  0.11294515,  0.23771362, -0.39065424,\n",
       "        -0.34900036, -0.29941422, -0.16527915],\n",
       "       [-0.33694664,  0.14646076, -0.62279296, -0.13871029,  0.46268064,\n",
       "         0.21392056, -0.6828361 ,  0.20112647, -0.5739584 , -0.07129148,\n",
       "        -0.03551545, -0.0780242 , -0.3732799 , -0.16221766, -0.19178775,\n",
       "        -0.6829699 , -0.39406958, -0.09489785,  0.24325009,  0.4967251 ,\n",
       "         0.34103388, -0.22422343,  0.2302437 ,  0.18511055, -0.29758796,\n",
       "        -0.16162081,  0.08358112,  0.06012698],\n",
       "       [-0.11962943, -0.43136078, -0.32188916, -0.19166657, -0.01314483,\n",
       "        -0.13979553, -0.19074066, -0.1124658 ,  0.29112348,  0.41107005,\n",
       "        -0.36559206, -0.7133602 , -0.1281714 ,  0.20475757,  0.39818949,\n",
       "         0.00694395, -0.24704415, -0.01539483, -0.49385643,  0.43905947,\n",
       "         0.241584  , -0.43946823,  0.41509643,  0.32223833, -0.6004722 ,\n",
       "        -0.18156199, -0.15851931, -0.12789465],\n",
       "       [-0.15419167, -0.01407822, -0.5388659 ,  0.5135901 ,  0.54337704,\n",
       "         0.39888725, -0.3286775 , -0.32814988, -0.31182066,  0.15305549,\n",
       "        -0.5051426 , -0.644416  , -0.11980062, -0.17895252,  0.02412373,\n",
       "        -0.4961153 , -0.3522767 ,  0.09115047,  0.599653  ,  0.09560136,\n",
       "        -0.15440896, -0.6208605 ,  0.29577175,  0.2712532 ,  0.02293816,\n",
       "        -0.5080638 ,  0.16451448,  0.03653714],\n",
       "       [ 0.00136433, -0.02890687, -0.63081664, -0.08020102,  0.42797363,\n",
       "         0.2324746 , -0.46978644,  0.0291799 ,  0.0942408 ,  0.41595793,\n",
       "        -0.25330153, -0.51968527,  0.07603142,  0.11462551,  0.14706977,\n",
       "        -0.6528784 , -0.5418763 ,  0.14350171,  0.02561106,  0.5693624 ,\n",
       "         0.30002415, -0.2130152 ,  0.47676396,  0.3508795 , -0.24483417,\n",
       "        -0.29479113,  0.18086612,  0.26832142],\n",
       "       [-0.03212019, -0.44992045, -0.45155182, -0.41104305,  0.19496046,\n",
       "        -0.18015066, -0.3413046 ,  0.12076008,  0.13812359,  0.38610572,\n",
       "         0.19981714,  0.01677725,  0.32245973, -0.04356144, -0.05606806,\n",
       "        -0.5194883 , -0.58460426,  0.1086343 , -0.04664801,  0.3064526 ,\n",
       "         0.29647174, -0.15538752,  0.11073672,  0.10212754, -0.7033149 ,\n",
       "        -0.2290516 ,  0.3118863 ,  0.3029425 ],\n",
       "       [ 0.24570182,  0.19468728, -0.7602074 , -0.12422321,  0.56699944,\n",
       "         0.45618346, -0.24747188,  0.02474768,  0.00108588,  0.33565524,\n",
       "        -0.09614199, -0.54246485, -0.24100211,  0.04053638,  0.14393175,\n",
       "        -0.3879444 , -0.49711317, -0.02092166, -0.03402415,  0.3924836 ,\n",
       "         0.18921834, -0.20490533,  0.31225613,  0.27413917, -0.48821828,\n",
       "        -0.22113842, -0.12661348, -0.19350737],\n",
       "       [ 0.02080565, -0.12371642, -0.36238477, -0.4761975 , -0.11231382,\n",
       "        -0.14665332,  0.18867977, -0.02882734, -0.12097907,  0.23203292,\n",
       "         0.08369899, -0.59936535, -0.13843146, -0.33610812,  0.15852727,\n",
       "         0.61146086,  0.01488331, -0.33633512, -0.47254533,  0.04093885,\n",
       "         0.07322405, -0.53815883,  0.39632526,  0.42563587, -0.18461749,\n",
       "        -0.36242133,  0.1898571 ,  0.29493874],\n",
       "       [-0.00199281,  0.04597009, -0.09930068, -0.15983032, -0.15513942,\n",
       "         0.21658331,  0.40234044, -0.19288914,  0.25899088,  0.43555412,\n",
       "        -0.18804047, -0.27602294,  0.1445999 ,  0.18194382,  0.3566817 ,\n",
       "        -0.1332697 , -0.4742969 , -0.13523237, -0.6516065 ,  0.47239655,\n",
       "         0.3267621 , -0.07756813,  0.5903312 ,  0.48654607, -0.4472417 ,\n",
       "        -0.11339112,  0.02506321, -0.13072729],\n",
       "       [ 0.1952773 , -0.1799236 , -0.17601722, -0.015037  , -0.4013907 ,\n",
       "         0.06583355,  0.37553695, -0.3037175 ,  0.44856533,  0.6094717 ,\n",
       "        -0.29577628,  0.01149496,  0.10437935,  0.16400377,  0.22075522,\n",
       "        -0.45192617, -0.43871403, -0.29569015, -0.06184308,  0.13506666,\n",
       "         0.1787369 , -0.04219029,  0.1153698 , -0.01755285, -0.48579365,\n",
       "         0.13463834, -0.17039126, -0.46894544],\n",
       "       [ 0.32908657,  0.14067559, -0.11580149, -0.34629542, -0.17119302,\n",
       "         0.12962656,  0.43655607, -0.18087617,  0.41441298,  0.50679505,\n",
       "        -0.5170036 , -0.3413719 ,  0.30758575,  0.23329666,  0.53850514,\n",
       "        -0.59968233, -0.620208  ,  0.05526952, -0.2219226 ,  0.08089346,\n",
       "        -0.13406804, -0.389042  ,  0.21843134,  0.2392982 , -0.18795897,\n",
       "        -0.5580014 ,  0.02246309, -0.20762108],\n",
       "       [ 0.15498708, -0.25425225, -0.16239949, -0.21407485, -0.2974325 ,\n",
       "         0.08453819,  0.54348016, -0.15330216,  0.13403158,  0.23878878,\n",
       "        -0.16408132,  0.01881276,  0.15834807, -0.23891468, -0.20183346,\n",
       "        -0.33090925, -0.26657134, -0.31915477, -0.07847102,  0.30163172,\n",
       "         0.37634116,  0.02185726,  0.09583835,  0.1057242 , -0.3446854 ,\n",
       "        -0.53862256,  0.27362272,  0.30166137],\n",
       "       [-0.22069879, -0.2195201 , -0.32727796, -0.4496299 ,  0.12872027,\n",
       "        -0.1875601 , -0.7123176 , -0.23378624,  0.40152058,  0.2548215 ,\n",
       "        -0.35357362, -0.20101464, -0.00651058,  0.35054868,  0.31196153,\n",
       "        -0.58296734,  0.00147316,  0.15838231,  0.05047086, -0.08661453,\n",
       "         0.31784648, -0.14359385, -0.09877454, -0.04283861, -0.66250104,\n",
       "         0.30409622, -0.1203289 , -0.19503824],\n",
       "       [ 0.12225573, -0.07474914,  0.24919559, -0.14224882, -0.39445543,\n",
       "        -0.2857335 ,  0.5598388 , -0.5213485 ,  0.2119513 ,  0.3795546 ,\n",
       "         0.1749811 , -0.4167013 ,  0.28064555,  0.09030759,  0.29203138,\n",
       "         0.08972903, -0.5710374 , -0.06042252, -0.5407647 ,  0.4113588 ,\n",
       "         0.14803432, -0.41042724,  0.40671992,  0.37747553, -0.3179173 ,\n",
       "        -0.06201126,  0.2539863 ,  0.19890848],\n",
       "       [ 0.00244958, -0.20122215, -0.03724514,  0.10284137,  0.02228217,\n",
       "        -0.39885262, -0.588204  , -0.38624448,  0.16096051,  0.40168795,\n",
       "        -0.34208903, -0.00261324,  0.22000965, -0.05888654,  0.08521526,\n",
       "        -0.6619207 , -0.16204014,  0.08885874, -0.06967891,  0.11317261,\n",
       "         0.20375033, -0.5739842 ,  0.08277267, -0.05495812, -0.6828244 ,\n",
       "         0.20162566,  0.28167167,  0.18255655],\n",
       "       [-0.095885  , -0.22202623, -0.1882905 , -0.33471468,  0.02993389,\n",
       "        -0.24562462, -0.45442456, -0.46793696,  0.5271899 ,  0.37099546,\n",
       "        -0.46773854, -0.5001476 ,  0.2111117 ,  0.52652895,  0.43259895,\n",
       "        -0.79504573, -0.39288062,  0.36721233,  0.03807021,  0.04315894,\n",
       "         0.3142745 , -0.00966646,  0.1097479 ,  0.04458138, -0.7093132 ,\n",
       "        -0.10322796,  0.2205403 ,  0.0184271 ],\n",
       "       [-0.44791895, -0.17551109,  0.20211981,  0.5849519 ,  0.56104946,\n",
       "         0.27249807, -0.3613287 , -0.56022143, -0.20138492, -0.08359269,\n",
       "        -0.28846928, -0.4501128 , -0.3230516 , -0.1995951 , -0.24866334,\n",
       "        -0.5911081 , -0.48257732, -0.21022113,  0.3112075 ,  0.5612587 ,\n",
       "         0.4375114 , -0.55942005,  0.17670086,  0.07595363, -0.34975567,\n",
       "        -0.10840847,  0.47505665,  0.4550724 ],\n",
       "       [-0.25946966, -0.4959686 , -0.29858294,  0.30558077,  0.22249894,\n",
       "         0.20241179, -0.29808056,  0.46064943,  0.04579432,  0.11661877,\n",
       "        -0.46250102, -0.19360341,  0.08788678, -0.32664683, -0.5314871 ,\n",
       "        -0.25070426,  0.1772311 , -0.01502928,  0.60049045, -0.04767155,\n",
       "        -0.33718953, -0.6980289 ,  0.0373076 , -0.10466101,  0.12004171,\n",
       "        -0.15593497,  0.33933192,  0.38016778],\n",
       "       [ 0.01165607,  0.12555201, -0.253207  , -0.08439919, -0.2074423 ,\n",
       "         0.27970597,  0.54742634, -0.03738347,  0.11120814,  0.32001758,\n",
       "        -0.5797108 , -0.19544092,  0.13639069,  0.09572139,  0.2071522 ,\n",
       "        -0.48367834, -0.59171623, -0.26036242, -0.13232413,  0.14220816,\n",
       "         0.08259532, -0.1274523 ,  0.12166701,  0.00098523, -0.39801416,\n",
       "         0.11259872, -0.00646481, -0.4054506 ],\n",
       "       [-0.21365832, -0.36644614, -0.50947595, -0.17179905,  0.17239359,\n",
       "         0.0236118 , -0.5679157 ,  0.19651727,  0.1967116 ,  0.253122  ,\n",
       "        -0.3282425 , -0.282964  ,  0.18001464, -0.15456346, -0.22282471,\n",
       "        -0.49813497, -0.08606686,  0.15215763,  0.10065936,  0.2955663 ,\n",
       "         0.3196346 , -0.5024448 , -0.00211563,  0.07780271, -0.5761906 ,\n",
       "        -0.17085771,  0.27581534,  0.28525978],\n",
       "       [-0.38677397, -0.65098643, -0.08309644,  0.35530114, -0.17184731,\n",
       "        -0.32960984, -0.29807058,  0.17682886,  0.48003915,  0.5925254 ,\n",
       "        -0.7092457 , -0.25090167,  0.32980883, -0.06190522,  0.19848317,\n",
       "        -0.50195676, -0.04097473,  0.12702271,  0.4045406 ,  0.22268781,\n",
       "         0.03500399, -0.64137673,  0.3043969 ,  0.13525325, -0.5009754 ,\n",
       "        -0.1266815 ,  0.02235075, -0.12229902],\n",
       "       [-0.5350517 , -0.3061767 , -0.6383357 ,  0.32741064,  0.4817274 ,\n",
       "         0.41435263, -0.43143624,  0.1473435 , -0.32553196,  0.20865948,\n",
       "        -0.31083533, -0.31309834, -0.22471629, -0.21695836, -0.07859672,\n",
       "        -0.7141353 , -0.34727168,  0.00278661,  0.54819024,  0.27127162,\n",
       "         0.07797409, -0.48484275,  0.27395055,  0.13705735,  0.11476266,\n",
       "        -0.39523152,  0.25921938,  0.11569279],\n",
       "       [-0.43271244,  0.07863899, -0.28355432, -0.06935127, -0.15185949,\n",
       "         0.35881963,  0.6516284 , -0.13572021, -0.11123911,  0.0977759 ,\n",
       "        -0.6281904 , -0.3640538 ,  0.28128406,  0.25744817,  0.37318516,\n",
       "        -0.34751183, -0.61997396,  0.16127475, -0.20586847,  0.09033416,\n",
       "         0.24050923, -0.3151661 ,  0.09847806,  0.25777647, -0.529505  ,\n",
       "         0.08298201,  0.2494149 ,  0.11292376],\n",
       "       [-0.14012569, -0.4131279 ,  0.04471784,  0.13072778, -0.49734205,\n",
       "        -0.02158104,  0.46108043, -0.21104953,  0.5483093 ,  0.51776016,\n",
       "        -0.4081074 , -0.18070002,  0.07084151,  0.1162647 ,  0.04160854,\n",
       "        -0.36595216, -0.3584248 , -0.37923396,  0.10365567,  0.3079933 ,\n",
       "         0.4345166 ,  0.10300198,  0.11155102,  0.08578134, -0.48988444,\n",
       "        -0.0938718 , -0.07905108, -0.19959609],\n",
       "       [ 0.06164822, -0.08096167, -0.42782396, -0.4465426 ,  0.0483956 ,\n",
       "         0.28264007,  0.15928622, -0.2391163 ,  0.19920114,  0.15259817,\n",
       "        -0.5537714 , -0.6823225 , -0.22477362,  0.22391038,  0.34956303,\n",
       "        -0.06963931, -0.38346273, -0.2996136 , -0.35162786,  0.61075854,\n",
       "         0.3846453 ,  0.03944919,  0.47841418,  0.3519792 , -0.12393246,\n",
       "        -0.29734042,  0.0204076 , -0.13810672],\n",
       "       [-0.12654795,  0.01201441, -0.32349077, -0.37021708, -0.0045878 ,\n",
       "         0.3545029 ,  0.27825755, -0.37601665,  0.06276227,  0.14025626,\n",
       "        -0.45350313, -0.3889179 , -0.00119293,  0.16995986,  0.32888937,\n",
       "        -0.24610855, -0.37265703, -0.05465908, -0.39653698,  0.5382011 ,\n",
       "         0.29437807, -0.10063791,  0.48643032,  0.37609336, -0.37035635,\n",
       "        -0.2817333 ,  0.1167347 , -0.06403197],\n",
       "       [-0.29614952, -0.5611985 ,  0.15840696,  0.00713306, -0.35686153,\n",
       "        -0.17005047,  0.28849494, -0.0313856 ,  0.55520904,  0.6105492 ,\n",
       "        -0.68772054, -0.50991607,  0.17718345,  0.19917744,  0.55440485,\n",
       "        -0.23116034, -0.320002  , -0.12581623,  0.42010367,  0.18444072,\n",
       "        -0.22510834, -0.6426236 ,  0.3832526 ,  0.08572137, -0.2912325 ,\n",
       "         0.07672117, -0.0833817 , -0.4389748 ]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br.g_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a2dbad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fa_tfpy",
   "language": "python",
   "name": "fa_tfpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
